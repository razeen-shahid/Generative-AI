{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10667828,"sourceType":"datasetVersion","datasetId":6606912},{"sourceId":10694377,"sourceType":"datasetVersion","datasetId":6626686}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\n\n# Extract poetry column\npoetry_lines = df[\"Poetry\"].astype(str).tolist()\n\n# Tokenization\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(poetry_lines)\ntotal_words = len(tokenizer.word_index) + 1  # Add 1 for padding token\n\n# Convert text to sequences\ninput_sequences = []\nfor line in poetry_lines:\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        input_sequences.append(token_list[:i+1])\n\n# Pad sequences\nmax_sequence_length = max([len(seq) for seq in input_sequences])\n#max_sequence_length=20\ninput_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n\n# Split into features (X) and labels (y)\nX, y = input_sequences[:, :-1], input_sequences[:, -1]\ny = tf.keras.utils.to_categorical(y, num_classes=total_words)\n\nprint(f\"Total words in vocabulary: {total_words}\")\nprint(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T09:44:24.827651Z","iopub.execute_input":"2025-02-08T09:44:24.827953Z","iopub.status.idle":"2025-02-08T09:44:38.627280Z","shell.execute_reply.started":"2025-02-08T09:44:24.827929Z","shell.execute_reply":"2025-02-08T09:44:38.626486Z"}},"outputs":[{"name":"stdout","text":"Total words in vocabulary: 10523\nShape of X: (184779, 565), Shape of y: (184779, 10523)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\noptimizer = Adam(learning_rate=0.001)  # Lower learning rate\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Define model\nmodel = Sequential([\n    Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_length-1),\n    LSTM(100, return_sequences=True),  # First LSTM layer (return_sequences=True for next LSTM layer)\n    LSTM(100),                         # Second LSTM layer (no need for return_sequences)\n    Dense(total_words, activation=\"softmax\")  # Output layer for predicting words\n])\n\n# Compile model\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n\n# Model summary\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T09:46:09.642429Z","iopub.execute_input":"2025-02-08T09:46:09.643084Z","iopub.status.idle":"2025-02-08T09:46:10.536749Z","shell.execute_reply.started":"2025-02-08T09:46:09.643055Z","shell.execute_reply":"2025-02-08T09:46:10.536059Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Define training parameters\nepochs = 20\nbatch_size = 64\n\n# Train the model\nhistory = model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T09:46:18.664827Z","iopub.execute_input":"2025-02-08T09:46:18.665143Z","iopub.status.idle":"2025-02-08T10:39:02.306945Z","shell.execute_reply.started":"2025-02-08T09:46:18.665121Z","shell.execute_reply":"2025-02-08T10:39:02.306106Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 53ms/step - accuracy: 0.0616 - loss: 6.8733\nEpoch 2/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.0844 - loss: 6.2686\nEpoch 3/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1007 - loss: 6.0690\nEpoch 4/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1154 - loss: 5.8713\nEpoch 5/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 55ms/step - accuracy: 0.1256 - loss: 5.7143\nEpoch 6/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1315 - loss: 5.5813\nEpoch 7/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 54ms/step - accuracy: 0.1440 - loss: 5.3184\nEpoch 9/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1503 - loss: 5.2074\nEpoch 10/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1569 - loss: 5.0759\nEpoch 11/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1623 - loss: 4.9829\nEpoch 12/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 54ms/step - accuracy: 0.1668 - loss: 4.8918\nEpoch 13/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1721 - loss: 4.8042\nEpoch 14/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 55ms/step - accuracy: 0.1774 - loss: 4.7176\nEpoch 15/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1833 - loss: 4.6330\nEpoch 16/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 54ms/step - accuracy: 0.1890 - loss: 4.5631\nEpoch 17/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 54ms/step - accuracy: 0.1968 - loss: 4.4807\nEpoch 18/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 54ms/step - accuracy: 0.2040 - loss: 4.4175\nEpoch 19/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 54ms/step - accuracy: 0.2122 - loss: 4.3510\nEpoch 20/20\n\u001b[1m2888/2888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 54ms/step - accuracy: 0.2202 - loss: 4.2836\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Save the model\nmodel.save(\"roman_urdu_lstm_model.h5\")\nprint(\"Model saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:20:31.538597Z","iopub.execute_input":"2025-02-08T16:20:31.538923Z","iopub.status.idle":"2025-02-08T16:20:31.606634Z","shell.execute_reply.started":"2025-02-08T16:20:31.538896Z","shell.execute_reply":"2025-02-08T16:20:31.605588Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-04c8b7cf9ed4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roman_urdu_lstm_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the model\nloaded_model = load_model(\"roman_urdu_lstm_model.h5\")\nprint(\"Model loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:16:10.415897Z","iopub.execute_input":"2025-02-05T10:16:10.416215Z","iopub.status.idle":"2025-02-05T10:16:10.606634Z","shell.execute_reply.started":"2025-02-05T10:16:10.416191Z","shell.execute_reply":"2025-02-05T10:16:10.605701Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import random\n\n# Function to generate poetry based on input seed\ndef generate_poetry(model, tokenizer, seed_text, max_sequence_length, num_words=50):\n    # Tokenize the seed text\n    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n    \n    # Pad the input sequence to match the model's expected input length\n    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n\n    predicted_text = seed_text\n\n    for _ in range(num_words):\n        # Predict the next word\n        predicted_probs = model.predict(token_list, verbose=0)\n        predicted_word_idx = np.argmax(predicted_probs)\n        \n        # Convert index to word\n        predicted_word = tokenizer.index_word.get(predicted_word_idx, '')\n        \n        # Append the word to the generated text\n        predicted_text += ' ' + predicted_word\n        \n        # Update token list for next word prediction\n        token_list = pad_sequences([token_list[0].tolist() + [predicted_word_idx]], maxlen=max_sequence_length-1, padding='pre')\n\n    return predicted_text\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:40:54.003222Z","iopub.execute_input":"2025-02-05T11:40:54.003621Z","iopub.status.idle":"2025-02-05T11:40:54.009340Z","shell.execute_reply.started":"2025-02-05T11:40:54.003587Z","shell.execute_reply":"2025-02-05T11:40:54.008365Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Example usage: Generate poetry based on user input\nseed_input = input(\"Enter a seed for poetry generation: \")\ngenerated_poetry = generate_poetry(loaded_model, tokenizer, seed_input, max_sequence_length)\nprint(\"\\nGenerated Poetry:\\n\", generated_poetry)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of 4 different test inputs\ntest_inputs = [\n    \"dil ki baat\",\n    \"zindagi ka safar\",\n    \"mohabbat ka rang\",\n    \"khushiyan aur gham\"\n]\n\n# Generate poetry for each input\nfor idx, seed_input in enumerate(test_inputs, 1):\n    print(f\"\\nTest {idx}: Seed Input: {seed_input}\")\n    generated_poetry = generate_poetry(loaded_model, tokenizer, seed_input, max_sequence_length)\n    print(f\"\\nGenerated Poetry:\\n{generated_poetry}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:40:58.041902Z","iopub.execute_input":"2025-02-05T11:40:58.042253Z","iopub.status.idle":"2025-02-05T11:41:14.915559Z","shell.execute_reply.started":"2025-02-05T11:40:58.042223Z","shell.execute_reply":"2025-02-05T11:41:14.914551Z"}},"outputs":[{"name":"stdout","text":"\nTest 1: Seed Input: dil ki baat\n\nGenerated Poetry:\ndil ki baat hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī\n\n\nTest 2: Seed Input: zindagi ka safar\n\nGenerated Poetry:\nzindagi ka safar hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī\n\n\nTest 3: Seed Input: mohabbat ka rang\n\nGenerated Poetry:\nmohabbat ka rang ī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne\n\n\nTest 4: Seed Input: khushiyan aur gham\n\nGenerated Poetry:\nkhushiyan aur gham bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne bhī hai ki ham ne\n\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"NOW TRYING WITH PYTORCH","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Load the dataset\nfile_path = \"/kaggle/input/romanurdudata/Roman-Urdu-Poetry.csv\"\ndf = pd.read_csv(file_path)\n\n# Extract poetry column\npoetry_lines = df[\"Poetry\"].astype(str).tolist()\n\n# Tokenization\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(poetry_lines)\ntotal_words = len(tokenizer.word_index) + 1  # Add 1 for padding token\n\n# Convert text to sequences\ninput_sequences = []\nfor line in poetry_lines:\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        input_sequences.append(token_list[:i+1])\n\n# Pad sequences\nmax_sequence_length = max([len(seq) for seq in input_sequences])\ninput_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n\n# Split into features (X) and labels (y)\nX, y = input_sequences[:, :-1], input_sequences[:, -1]\n\n# Convert to PyTorch tensors\nX_tensor = torch.tensor(X, dtype=torch.long)\ny_tensor = torch.tensor(y, dtype=torch.long)\n\n# Create DataLoader\ndataset = TensorDataset(X_tensor, y_tensor)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n\n# Define the LSTM model\nclass PoetryLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, seq_length):\n        super(PoetryLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, vocab_size)  # Bidirectional: *2\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, _ = self.lstm(embedded)\n        output = self.fc(lstm_out[:, -1, :])  # Take the output of the last LSTM step\n        return output\n\nprint(\"start training\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T12:11:46.496500Z","iopub.execute_input":"2025-02-05T12:11:46.496784Z","iopub.status.idle":"2025-02-05T12:11:49.137195Z","shell.execute_reply.started":"2025-02-05T12:11:46.496763Z","shell.execute_reply":"2025-02-05T12:11:49.136175Z"}},"outputs":[{"name":"stdout","text":"start training\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Model initialization\nembedding_dim = 100\nhidden_dim = 100\nmodel = PoetryLSTM(vocab_size=total_words, embedding_dim=embedding_dim, hidden_dim=hidden_dim, seq_length=max_sequence_length-1)\n\n# Define loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nepochs = 20\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0\n    for inputs, targets in dataloader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader)}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T12:11:56.640493Z","iopub.execute_input":"2025-02-05T12:11:56.640772Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to generate poetry based on input seed\ndef generate_poetry(model, tokenizer, seed_text, max_sequence_length, num_words=50):\n    model.eval()  # Set model to evaluation mode\n    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n    token_tensor = torch.tensor(token_list, dtype=torch.long)\n    \n    predicted_text = seed_text\n\n    for _ in range(num_words):\n        with torch.no_grad():\n            output = model(token_tensor)\n            predicted_word_idx = torch.argmax(output, dim=1).item()\n\n        predicted_word = tokenizer.index_word.get(predicted_word_idx, '')\n        predicted_text += ' ' + predicted_word\n\n        token_list = token_list[0].tolist() + [predicted_word_idx]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n        token_tensor = torch.tensor(token_list, dtype=torch.long)\n\n    return predicted_text\n\n# Test with 4 different inputs\ntest_inputs = [\n    \"dil ki baat\",\n    \"zindagi ka safar\",\n    \"mohabbat ka rang\",\n    \"khushiyan aur gham\"\n]\n\nfor idx, seed_input in enumerate(test_inputs, 1):\n    print(f\"\\nTest {idx}: Seed Input: {seed_input}\")\n    generated_poetry = generate_poetry(model, tokenizer, seed_input, max_sequence_length)\n    print(f\"\\nGenerated Poetry:\\n{generated_poetry}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T11:50:55.156423Z","iopub.status.idle":"2025-02-05T11:50:55.156809Z","shell.execute_reply":"2025-02-05T11:50:55.156679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Load the dataset\nfile_path = \"/kaggle/input/rayyan/Roman-Urdu-Poetry.csv\"\ndf = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:21:05.962669Z","iopub.execute_input":"2025-02-08T16:21:05.963019Z","iopub.status.idle":"2025-02-08T16:21:19.257368Z","shell.execute_reply.started":"2025-02-08T16:21:05.962956Z","shell.execute_reply":"2025-02-08T16:21:19.256694Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\n# Extract poetry column\npoetry_lines = df[\"Poetry\"].astype(str).tolist()\n\n# Tokenization\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(poetry_lines)\ntotal_words = len(tokenizer.word_index) + 1  # Add 1 for padding token\n\n# Convert text to sequences\ninput_sequences = []\nfor line in poetry_lines:\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        input_sequences.append(token_list[:i+1])\n\n# Pad sequences\nmax_sequence_length = max([len(seq) for seq in input_sequences])\ninput_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n\n# Split into features (X) and labels (y)\nX, y = input_sequences[:, :-1], input_sequences[:, -1]\n\n# Convert to PyTorch tensors\nX_tensor = torch.tensor(X, dtype=torch.long)\ny_tensor = torch.tensor(y, dtype=torch.long)\n\n# Create DataLoader\ndataset = TensorDataset(X_tensor, y_tensor)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:21:21.936696Z","iopub.execute_input":"2025-02-08T16:21:21.936997Z","iopub.status.idle":"2025-02-08T16:21:24.465098Z","shell.execute_reply.started":"2025-02-08T16:21:21.936956Z","shell.execute_reply":"2025-02-08T16:21:24.464208Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Define the LSTM model\nclass PoetryLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, seq_length):\n        super(PoetryLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, vocab_size)  # Bidirectional: *2\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        lstm_out, _ = self.lstm(embedded)\n        output = self.fc(lstm_out[:, -1, :])  # Take the output of the last LSTM step\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:22:01.158544Z","iopub.execute_input":"2025-02-08T16:22:01.158865Z","iopub.status.idle":"2025-02-08T16:22:01.163860Z","shell.execute_reply.started":"2025-02-08T16:22:01.158840Z","shell.execute_reply":"2025-02-08T16:22:01.163080Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n# Model initialization\nembedding_dim = 100\nhidden_dim = 100\nmodel = PoetryLSTM(vocab_size=total_words, embedding_dim=embedding_dim, hidden_dim=hidden_dim, seq_length=max_sequence_length-1)\n\n# Define loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nepochs = 20\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0\n    for inputs, targets in dataloader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:22:04.747958Z","iopub.execute_input":"2025-02-08T16:22:04.748325Z","iopub.status.idle":"2025-02-08T16:27:02.679431Z","shell.execute_reply.started":"2025-02-08T16:22:04.748290Z","shell.execute_reply":"2025-02-08T16:27:02.678126Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-8029a44865f2>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"\n# Function to generate poetry based on input seed\ndef generate_poetry(model, tokenizer, seed_text, max_sequence_length, num_words=50):\n    model.eval()  # Set model to evaluation mode\n    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n    token_tensor = torch.tensor(token_list, dtype=torch.long)\n    \n    predicted_text = seed_text\n\n    for _ in range(num_words):\n        with torch.no_grad():\n            output = model(token_tensor)\n            predicted_word_idx = torch.argmax(output, dim=1).item()\n\n        predicted_word = tokenizer.index_word.get(predicted_word_idx, '')\n        predicted_text += ' ' + predicted_word\n\n        token_list = token_list[0].tolist() + [predicted_word_idx]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n        token_tensor = torch.tensor(token_list, dtype=torch.long)\n\n    return predicted_text\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-05T12:25:37.453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Test with 4 different inputs\ntest_inputs = [\n    \"dil ki baat\",\n    \"zindagi ka safar\",\n    \"mohabbat ka rang\",\n    \"khushiyan aur gham\"\n]\n\nfor idx, seed_input in enumerate(test_inputs, 1):\n    print(f\"\\nTest {idx}: Seed Input: {seed_input}\")\n    generated_poetry = generate_poetry(model, tokenizer, seed_input, max_sequence_length)\n    print(f\"\\nGenerated Poetry:\\n{generated_poetry}\\n\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-05T12:25:37.453Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# New","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport time\nimport wandb  # Optional: for experiment tracking\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\nclass PoetryLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, seq_length, num_layers=2, dropout=0.2):\n        super(PoetryLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.dropout = nn.Dropout(dropout)\n        self.lstm = nn.LSTM(\n            embedding_dim, \n            hidden_dim, \n            num_layers=num_layers,\n            bidirectional=True,\n            dropout=dropout if num_layers > 1 else 0,\n            batch_first=True\n        )\n        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n        \n        # Initialize weights\n        self.init_weights()\n    \n    def init_weights(self):\n        for name, param in self.named_parameters():\n            if 'weight' in name:\n                nn.init.xavier_uniform_(param)\n            elif 'bias' in name:\n                nn.init.zeros_(param)\n    \n    def forward(self, x, hidden=None):\n        embedded = self.dropout(self.embedding(x))\n        output, hidden = self.lstm(embedded, hidden)\n        output = self.dropout(output)\n        output = self.fc(output[:, -1, :])  # Take only the last output\n        return output, hidden\n\nclass EarlyStopping:\n    def __init__(self, patience=7, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n        self.best_model = None\n\n    def __call__(self, val_loss, model):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            self.best_model = model.state_dict()\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.best_model = model.state_dict()\n            self.counter = 0\n\ndef train_model(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    scheduler,\n    num_epochs,\n    device,\n    early_stopping=None,\n    use_wandb=False\n):\n    \"\"\"\n    Enhanced training function with validation, early stopping, and learning rate scheduling\n    \n    Args:\n        model: The neural network model\n        train_loader: DataLoader for training data\n        val_loader: DataLoader for validation data\n        criterion: Loss function\n        optimizer: Optimizer\n        scheduler: Learning rate scheduler\n        num_epochs: Number of training epochs\n        device: Device to train on (cuda/cpu)\n        early_stopping: EarlyStopping instance\n        use_wandb: Whether to log metrics to Weights & Biases\n    \"\"\"\n    \n    # Training history\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'train_perplexity': [],\n        'val_perplexity': []\n    }\n    \n    # Move model to device\n    model = model.to(device)\n    \n    # Training loop\n    for epoch in range(num_epochs):\n        start_time = time.time()\n        \n        # Training phase\n        model.train()\n        train_loss = 0\n        train_batches = 0\n        \n        # Progress bar for training\n        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n        for inputs, targets in train_pbar:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            # Zero gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs, _ = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            # Backward pass and optimization\n            loss.backward()\n            \n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            \n            # Update metrics\n            train_loss += loss.item()\n            train_batches += 1\n            train_pbar.set_postfix({'loss': train_loss/train_batches})\n        \n        avg_train_loss = train_loss / train_batches\n        train_perplexity = np.exp(avg_train_loss)\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0\n        val_batches = 0\n        \n        # Progress bar for validation\n        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n        with torch.no_grad():\n            for inputs, targets in val_pbar:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs, _ = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                val_loss += loss.item()\n                val_batches += 1\n                val_pbar.set_postfix({'loss': val_loss/val_batches})\n        \n        avg_val_loss = val_loss / val_batches\n        val_perplexity = np.exp(avg_val_loss)\n        \n        # Update learning rate\n        scheduler.step(avg_val_loss)\n        \n        # Update history\n        history['train_loss'].append(avg_train_loss)\n        history['val_loss'].append(avg_val_loss)\n        history['train_perplexity'].append(train_perplexity)\n        history['val_perplexity'].append(val_perplexity)\n        \n        # Log metrics\n        if use_wandb:\n            wandb.log({\n                'train_loss': avg_train_loss,\n                'val_loss': avg_val_loss,\n                'train_perplexity': train_perplexity,\n                'val_perplexity': val_perplexity,\n                'learning_rate': optimizer.param_groups[0]['lr']\n            })\n        \n        # Print epoch summary\n        epoch_time = time.time() - start_time\n        print(f'\\nEpoch {epoch+1}/{num_epochs} - {epoch_time:.2f}s')\n        print(f'Train Loss: {avg_train_loss:.4f} - Train Perplexity: {train_perplexity:.2f}')\n        print(f'Val Loss: {avg_val_loss:.4f} - Val Perplexity: {val_perplexity:.2f}')\n        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}\\n')\n        \n        # Early stopping\n        if early_stopping is not None:\n            early_stopping(avg_val_loss, model)\n            if early_stopping.early_stop:\n                print(\"Early stopping triggered\")\n                model.load_state_dict(early_stopping.best_model)\n                break\n    \n    return model, history\n\ndef plot_training_history(history):\n    \"\"\"Plot training history\"\"\"\n    plt.figure(figsize=(12, 4))\n    \n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(history['train_loss'], label='Train')\n    plt.plot(history['val_loss'], label='Validation')\n    plt.title('Loss Over Time')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    # Plot perplexity\n    plt.subplot(1, 2, 2)\n    plt.plot(history['train_perplexity'], label='Train')\n    plt.plot(history['val_perplexity'], label='Validation')\n    plt.title('Perplexity Over Time')\n    plt.xlabel('Epoch')\n    plt.ylabel('Perplexity')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# Example usage:\n\ndef prepare_data(file_path):\n    # Load the dataset\n    df = pd.read_csv(file_path)\n    \n    # Extract poetry column\n    poetry_lines = df[\"Poetry\"].astype(str).tolist()\n    \n    # Tokenization\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(poetry_lines)\n    total_words = len(tokenizer.word_index) + 1\n    \n    # Convert text to sequences\n    input_sequences = []\n    for line in poetry_lines:\n        token_list = tokenizer.texts_to_sequences([line])[0]\n        for i in range(1, len(token_list)):\n            input_sequences.append(token_list[:i+1])\n    \n    # Pad sequences\n    max_sequence_length = max([len(seq) for seq in input_sequences])\n    input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n    \n    # Split into features (X) and labels (y)\n    X = input_sequences[:, :-1]\n    y = input_sequences[:, -1]\n    \n    # Convert to PyTorch tensors\n    X_tensor = torch.tensor(X, dtype=torch.long)\n    y_tensor = torch.tensor(y, dtype=torch.long)\n    \n    return X_tensor, y_tensor, tokenizer, total_words, max_sequence_length\n\n\ndef prepare_training(X_tensor, y_tensor, batch_size=32, val_split=0.1):\n    \"\"\"Prepare data for training\"\"\"\n    # Create train/val split\n    train_size = int((1 - val_split) * len(X_tensor))\n    val_size = len(X_tensor) - train_size\n    \n    train_dataset, val_dataset = random_split(\n        TensorDataset(X_tensor, y_tensor),\n        [train_size, val_size]\n    )\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    return train_loader, val_loader\n\ndef train_poetry_model(X_tensor, y_tensor, vocab_size, config=None):\n    \"\"\"Main training function with configuration\"\"\"\n    if config is None:\n        config = {\n            'embedding_dim': 256,\n            'hidden_dim': 512,\n            'num_layers': 2,\n            'dropout': 0.3,\n            'batch_size': 64,\n            'learning_rate': 0.001,\n            'num_epochs': 30,\n            'patience': 5,\n            'use_wandb': False\n        }\n    \n    # Prepare data\n    train_loader, val_loader = prepare_training(\n        X_tensor, y_tensor, \n        batch_size=config['batch_size']\n    )\n    \n    # Initialize model\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = PoetryLSTM(\n        vocab_size=vocab_size,\n        embedding_dim=config['embedding_dim'],\n        hidden_dim=config['hidden_dim'],\n        seq_length=X_tensor.shape[1],\n        num_layers=config['num_layers'],\n        dropout=config['dropout']\n    )\n    \n    # Initialize training components\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(\n        model.parameters(),\n        lr=config['learning_rate'],\n        weight_decay=0.01\n    )\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        mode='min',\n        factor=0.5,\n        patience=3,\n        verbose=True\n    )\n    early_stopping = EarlyStopping(patience=config['patience'])\n    \n    # Initialize wandb if needed\n    if config['use_wandb']:\n        wandb.init(project=\"urdu-poetry-generator\", config=config)\n    \n    # Train model\n    model, history = train_model(\n        model,\n        train_loader,\n        val_loader,\n        criterion,\n        optimizer,\n        scheduler,\n        config['num_epochs'],\n        device,\n        early_stopping,\n        config['use_wandb']\n    )\n    \n    # Plot training history\n    plot_training_history(history)\n    \n    return model, history\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:52:10.021333Z","iopub.execute_input":"2025-02-08T16:52:10.021646Z","iopub.status.idle":"2025-02-08T16:52:10.045485Z","shell.execute_reply.started":"2025-02-08T16:52:10.021610Z","shell.execute_reply":"2025-02-08T16:52:10.044592Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Configure for faster training\nconfig = {\n    'embedding_dim': 128,    # Reduced dimension\n    'hidden_dim': 256,      # Reduced dimension\n    'num_layers': 1,        # Single layer\n    'dropout': 0.2,         # Reduced dropout\n    'batch_size': 128,      # Increased batch size\n    'learning_rate': 0.1,  # Moderate learning rate\n    'num_epochs': 3,        # Reduced epochs\n    'patience': 2,          # Reduced patience\n    'use_wandb': False\n}\n\n# Prepare the data and train\nfile_path = \"/kaggle/input/rayyan/Roman-Urdu-Poetry.csv\"  # Adjust this path as needed\nX_tensor, y_tensor, tokenizer, total_words, max_sequence_length = prepare_data(file_path)\n\n# Train the model\nmodel, history = train_poetry_model(X_tensor, y_tensor, total_words, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T16:52:11.635762Z","iopub.execute_input":"2025-02-08T16:52:11.636076Z","iopub.status.idle":"2025-02-08T17:02:39.783140Z","shell.execute_reply.started":"2025-02-08T16:52:11.636053Z","shell.execute_reply":"2025-02-08T17:02:39.782393Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\nEpoch 1/3 [Train]: 100%|██████████| 1300/1300 [03:21<00:00,  6.46it/s, loss=13.8]\nEpoch 1/3 [Val]: 100%|██████████| 145/145 [00:07<00:00, 19.07it/s, loss=8.96]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/3 - 208.74s\nTrain Loss: 13.7730 - Train Perplexity: 958380.33\nVal Loss: 8.9624 - Val Perplexity: 7803.92\nLearning Rate: 0.100000\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/3 [Train]: 100%|██████████| 1300/1300 [03:21<00:00,  6.46it/s, loss=8.7] \nEpoch 2/3 [Val]: 100%|██████████| 145/145 [00:07<00:00, 19.01it/s, loss=8.29]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/3 - 208.84s\nTrain Loss: 8.7025 - Train Perplexity: 6018.21\nVal Loss: 8.2913 - Val Perplexity: 3988.86\nLearning Rate: 0.100000\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/3 [Train]: 100%|██████████| 1300/1300 [03:19<00:00,  6.51it/s, loss=8.29]\nEpoch 3/3 [Val]: 100%|██████████| 145/145 [00:07<00:00, 19.18it/s, loss=8.37]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/3 - 207.39s\nTrain Loss: 8.2889 - Train Perplexity: 3979.27\nVal Loss: 8.3671 - Val Perplexity: 4303.12\nLearning Rate: 0.100000\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACUrUlEQVR4nOzdeVwU5R8H8M/sLrvLudyXonjfAiqQR2pFqZl5leaF4NmhHXZanmWaZWX9NDUP8L5Kzaw0M628uBTvWxQUQRBhORfYnd8f6CpyiAjMAp/3q3nBzs7xmUHj8bvPPI8giqIIIiIiIiIiIiKiKiSTOgAREREREREREdU+LEoREREREREREVGVY1GKiIiIiIiIiIiqHItSRERERERERERU5ViUIiIiIiIiIiKiKseiFBERERERERERVTkWpYiIiIiIiIiIqMqxKEVERERERERERFWORSkiIiIiIiIiIqpyLEoREZmAGTNmQBAEqWMQERFRFdq3bx8EQcC+ffsq7Rzdu3dH9+7dK+34tQHbaUSVh0UpIkJoaCgEQUBkZKTUUcrkwIED6N+/P1xcXKBSqeDp6Ynx48cjNjZW6miFeHp6QhCEhy6hoaFSRyUiIqrx7rZ37i5qtRpNmzbFhAkTkJiYKHW8KhMfH48ZM2YgOjq6Uo7PdhoRPQqF1AGIiB7F//73P7z11lto2LAhJk6cCDc3N5w5cwbLli3Dxo0b8fvvv6NTp05SxwQAzJ8/HxkZGcbXv//+O9avX49vv/0Wjo6OxvWdOnXC8OHD8dFHH0kRk4iIqFb59NNP0aBBA+Tk5GD//v1YtGgRfv/9d5w8eRIWFhZSx6twf/75Z6HX8fHxmDlzJjw9PeHt7V2h52I7jYgeFYtSRFRtHDhwAG+//Ta6dOmCnTt3Fmo4vvbaa+jcuTNeeuklnDp1CnZ2dlWWKzMzE5aWlkXW9+vXr9DrhIQErF+/Hv369YOnp2eR7RUK/i+ZiIiosvXq1QsdOnQAAIwZMwYODg745ptv8Msvv2DIkCGPdeysrCyTK2wplcoqOQ/baURUHnx8j4jK7OjRo+jVqxdsbGxgZWWFZ555BocPHy60TV5eHmbOnIkmTZpArVbDwcEBXbp0we7du43bJCQkIDg4GHXr1oVKpYKbmxv69u2LK1eulHr+zz77DIIgYOXKlUUafI0aNcKXX36JGzduYMmSJQCAefPmQRAEXL16tcixJk+eDKVSidu3bxvXhYWFoWfPntBoNLCwsEC3bt1w4MCBQvvdHVPg9OnTGDp0KOzs7NClS5cy3b/SFDdWgSAImDBhAjZv3oyWLVvC3NwcHTt2xIkTJwAAS5YsQePGjaFWq9G9e/di719ZromIiKg2e/rppwEAMTExxnVr1qxB+/btYW5uDnt7e7zyyiuIi4srtF/37t3RunVrREVFoWvXrrCwsMDHH38MoODRsBdeeAF//vknvL29oVar0bJlS2zZsqVMmR72+/vMmTMwNzdHYGBgof32798PuVyODz/8sFDOu2NK7du3D76+vgCA4ODgQo+oTZ8+HWZmZkhKSiqSZ9y4cbC1tUVOTk6JmdlOYzuNqDxYlCKiMjl16hSefPJJHDt2DB988AGmTp2KmJgYdO/eHWFhYcbtZsyYgZkzZ+Kpp57CggUL8Mknn6BevXo4cuSIcZuBAwdi69atCA4Oxg8//IA333wT6enppY41kJWVhT179uDJJ59EgwYNit1m8ODBUKlU2LFjBwBg0KBBEAQBmzZtKrLtpk2b8Nxzzxk/qfv777/RtWtXaLVaTJ8+HbNnz0ZqaiqefvpphIeHF9n/5ZdfRlZWFmbPno2xY8eW7SaWw3///Yd3330XI0eOxIwZM3DmzBm88MILWLhwIb7//nu8/vrreP/993Ho0CGMGjWq0L6Pek1ERES10aVLlwAADg4OAIDPP/8cgYGBaNKkCb755hu8/fbb2LNnD7p27YrU1NRC+966dQu9evWCt7c35s+fj6eeesr43oULFzB48GD06tULc+bMgUKhwMsvv1zog7rilOX3d4sWLfDZZ59h9erV2L59O4CCHkFBQUFo3rw5Pv3002KP3aJFC+N748aNw+rVq7F69Wp07doVI0aMQH5+PjZu3Fhon9zcXPz0008YOHAg1Gp1scdlO43tNKJyE4mo1gsJCREBiBERESVu069fP1GpVIqXLl0yrouPjxetra3Frl27Gtd5eXmJvXv3LvE4t2/fFgGIX3311SNljI6OFgGIb731VqnbtW3bVrS3tze+7tixo9i+fftC24SHh4sAxFWrVomiKIoGg0Fs0qSJ2KNHD9FgMBi3y8rKEhs0aCA+++yzxnXTp08XAYhDhgx5pPyiKIpfffWVCECMiYkp8t7d494PgKhSqQptv2TJEhGA6OrqKmq1WuP6yZMnFzr2o1wTERFRbXC3vfPXX3+JSUlJYlxcnLhhwwbRwcFBNDc3F69duyZeuXJFlMvl4ueff15o3xMnTogKhaLQ+m7duokAxMWLFxc5V/369UUA4s8//2xcl5aWJrq5uYk+Pj7GdXv37hUBiHv37hVF8dF+f+v1erFLly6ii4uLmJycLL7xxhuiQqEo0p7r1q2b2K1bN+PriIgIEYAYEhJSJHfHjh1Ff3//Quu2bNlSKGNx2E4rwHYa0aNjTykieii9Xo8///wT/fr1Q8OGDY3r3dzcMHToUOzfvx9arRYAYGtri1OnTuHChQvFHsvc3BxKpRL79u0r1CX7YdLT0wEA1tbWpW5nbW1tzAIUfCoXFRVl/BQUADZu3AiVSoW+ffsCAKKjo3HhwgUMHToUt27dQnJyMpKTk5GZmYlnnnkG//77LwwGQ6HzvPrqq2XO/jieeeaZQuMa+Pv7AyjobXb/vbi7/vLlywDKd01ERES1QUBAAJycnODh4YFXXnkFVlZW2Lp1K+rUqYMtW7bAYDBg0KBBxt+dycnJcHV1RZMmTbB3795Cx1KpVAgODi72PO7u7ujfv7/xtY2NDQIDA3H06FEkJCQUu8+j/P6WyWQIDQ1FRkYGevXqhR9++AGTJ082jpdVHoGBgQgLCyvUblq7di08PDzQrVu3EvdjO60A22lEj45FKSJ6qKSkJGRlZaFZs2ZF3mvRogUMBoNxnIVPP/0UqampaNq0Kdq0aYP3338fx48fN26vUqkwd+5c/PHHH3BxcUHXrl3x5Zdfltg4u+vuL/a7jZ6SpKenF2oEvPzyy5DJZMau6KIoYvPmzcaxsQAYC2gjR46Ek5NToWXZsmXQ6XRIS0srdJ6SuqZXtHr16hV6rdFoAAAeHh7Frr9b6CvPNRERlebff/9Fnz594O7uDkEQsG3btkc+hiiKmDdvHpo2bQqVSoU6derg888/r/iwRKVYuHAhdu/ejb179+L06dO4fPkyevToAaDg96coimjSpEmR359nzpzBzZs3Cx2rTp06JQ4k3rhx4yLjEDVt2hQAShxH81F/fzdq1AgzZsxAREQEWrVqhalTp5brntx19xG7tWvXAgDS0tKwY8cODBs2rMi13I/ttAJspxE9Ok4hQEQVqmvXrrh06RJ++eUX/Pnnn1i2bBm+/fZbLF68GGPGjAEAvP322+jTpw+2bduGXbt2YerUqZgzZw7+/vtv+Pj4FHvcxo0bQ6FQFCpwPUin0+HcuXOFPiF0d3fHk08+iU2bNuHjjz/G4cOHERsbi7lz5xq3uftJ1FdffVXi1MhWVlaFXpubm5fpfjwuuVz+SOtFUQRQvmsiIipNZmYmvLy8MGrUKAwYMKBcx3jrrbfw559/Yt68eWjTpg1SUlKQkpJSwUmJSufn51dibyKDwQBBEPDHH38U+7u2stsD5fn9/eeffwIA4uPjcevWLbi6upb7/HZ2dnjhhRewdu1aTJs2DT/99BN0Oh2GDx9e6n5sp5VtPdtpREWxKEVED+Xk5AQLCwucO3euyHtnz56FTCYr9ImQvb09goODERwcjIyMDHTt2hUzZswwFqWAgk/23n33Xbz77ru4cOECvL298fXXX2PNmjXFZrC0tMRTTz2Fv//+G1evXkX9+vWLbLNp0ybodDq88MILhdYPHjwYr7/+Os6dO4eNGzfCwsICffr0KZQFKOhWHxAQ8Gg3x0TVxGsiImn16tULvXr1KvF9nU6HTz75BOvXr0dqaipat26NuXPnGmf9OnPmDBYtWoSTJ08ae95WVW8GorJq1KgRRFFEgwYNjL2ayuvixYsQRbFQD6Pz588DQKFHvh48P1D239+LFy/G7t278fnnn2POnDkYP348fvnll1L3Ka3HE1DwCF/fvn0RERGBtWvXwsfHB61atSp1H7bTHk1NvCai8uLje0T0UHK5HM899xx++eWXQt3NExMTsW7dOnTp0sXYxfrWrVuF9rWyskLjxo2h0+kAFMzO8uB0wo0aNYK1tbVxm5JMmTIFoigiKCgI2dnZhd6LiYnBBx98ADc3N4wfP77QewMHDoRcLsf69euxefNmvPDCC7C0tDS+3759ezRq1Ajz5s1DRkZGkfMWNzWyqauJ10REpm3ChAk4dOgQNmzYgOPHj+Pll19Gz549jY+p/Prrr2jYsCF27NiBBg0awNPTE2PGjGFPKTIpAwYMgFwux8yZM429Wu4SRbFIO6c08fHx2Lp1q/G1VqvFqlWr4O3tXWJvpkf5/R0TE4P3338fAwcOxMcff4x58+Zh+/btWLVqVam57raBHpxJ8K5evXrB0dERc+fOxT///PPQXlJ3sZ1WdjXxmojKiz2liMhoxYoV2LlzZ5H1b731FmbNmoXdu3ejS5cueP3116FQKLBkyRLodDp8+eWXxm1btmyJ7t27o3379rC3t0dkZCR++uknTJgwAUDBJ4TPPPMMBg0ahJYtW0KhUGDr1q1ITEzEK6+8Umq+rl27Yt68eZg0aRLatm2LoKAguLm54ezZs1i6dCkMBgN+//134/TBdzk7O+Opp57CN998g/T0dAwePLjQ+zKZDMuWLUOvXr3QqlUrBAcHo06dOrh+/Tr27t0LGxsb/Prrr+W9rZKoiddERKYrNjYWISEhiI2Nhbu7OwDgvffew86dOxESEoLZs2fj8uXLuHr1KjZv3oxVq1ZBr9fjnXfewUsvvYS///5b4isgKtCoUSPMmjULkydPxpUrV9CvXz9YW1sjJiYGW7duxbhx4/Dee++V6VhNmzbF6NGjERERARcXF6xYsQKJiYkICQkpcZ+y/v4WRRGjRo2Cubk5Fi1aBAAYP348fv75Z7z11lsICAgw/l0s7hptbW2xePFiWFtbw9LSEv7+/saei2ZmZnjllVewYMECyOVyDBkypEzXy3Za2dXEayIqN0nm/CMik3J3iuSSlri4OFEURfHIkSNijx49RCsrK9HCwkJ86qmnxIMHDxY61qxZs0Q/Pz/R1tZWNDc3F5s3by5+/vnnYm5uriiKonHK4ubNm4uWlpaiRqMR/f39xU2bNpU577///iv27dtXdHR0FM3MzMR69eqJY8eOFa9cuVLiPkuXLhUBiNbW1mJ2dnax2xw9elQcMGCA6ODgIKpUKrF+/frioEGDxD179hi3uTslcFJSUpnz3lWeqYbfeOONQutiYmJEAOJXX31VaP3dKaU3b978yNdERPSoAIhbt241vt6xY4cIQLS0tCy0KBQKcdCgQaIoiuLYsWNFAOK5c+eM+0VFRYkAxLNnz1b1JVAtdLe9ExER8dBtf/75Z7FLly7GP8vNmzcX33jjjUJ/frt16ya2atWq2P3r168v9u7dW9y1a5fYtm1bUaVSic2bNy/ye/ru7++9e/cWWv+w39/fffedCED8+eefC+0XGxsr2tjYiM8//3yhnN26dSu03S+//CK2bNlSVCgUIgAxJCSk0Pvh4eEiAPG555576L16ENtpbKcRPQpBFB/ol0pEREREVApBELB161b069cPQMEU7sOGDcOpU6eKDPBrZWUFV1dXTJ8+HbNnz0ZeXp7xvezsbFhYWODPP//Es88+W5WXQFSpPD090bp1a+zYsUPqKOVy7NgxeHt7Y9WqVRgxYoTUcYioBuPje0RERET0WHx8fKDX63Hz5k08+eSTxW7TuXNn5Ofn49KlS8ZBfu8O+lzcoMhEJJ2lS5fCysqq3DNtEhGVFYtSRERERPRQGRkZuHjxovF1TEwMoqOjYW9vj6ZNm2LYsGEIDAzE119/DR8fHyQlJWHPnj1o27YtevfujYCAALRr1w6jRo3C/PnzYTAY8MYbb+DZZ5997FnOiKhi/Prrrzh9+jR+/PFHTJgwodCA40RElYGP7xERERHRQ+3btw9PPfVUkfUjR45EaGgo8vLyMGvWLKxatQrXr1+Ho6MjnnjiCcycORNt2rQBUDAb2cSJE/Hnn3/C0tISvXr1wtdffw17e/uqvhyiSlVdH9/z9PREYmIievTogdWrV8Pa2lrqSERUw7EoRUREREREREREVU4mdQAiIiIiIiIiIqp9JC1K/fvvv+jTpw/c3d0hCAK2bdtW4ravvvoqBEHA/PnzqywfERERkal4lHbTXfv27UO7du2gUqnQuHFjhIaGVnpOIiIiorKSdKDzzMxMeHl5YdSoUaXO7LB161YcPnwY7u7uj3wOg8GA+Ph4WFtbQxCEx4lLREREtYQoikhPT4e7uztkMtPoWF7WdtNdMTEx6N27N1599VWsXbsWe/bswZgxY+Dm5oYePXqU+bxsSxEREdGjKmtbStKiVK9evdCrV69St7l+/TomTpyIXbt2oXfv3o98jvj4eHh4eJQ3IhEREdVicXFxqFu3rtQxAJSt3XS/xYsXo0GDBvj6668BAC1atMD+/fvx7bffPlJRim0pIiIiKq+HtaUkLUo9jMFgwIgRI/D++++jVatW5TrG3Rkj4uLiYGNjU5HxiIiIqIbSarXw8PCo1jNPHTp0CAEBAYXW9ejRA2+//Xap++l0Ouh0OuPru3PisC1FREREZVXWtpRJF6Xmzp0LhUKBN998s8z7PNiQSk9PBwDY2NiwIUVERESPpDo/rpaQkAAXF5dC61xcXKDVapGdnQ1zc/Ni95szZw5mzpxZZD3bUkRERPSoHtaWMo1BEooRFRWF7777DqGhoY/UIJwzZw40Go1xYXdzIiIiorKbPHky0tLSjEtcXJzUkYiIiKiGMtmi1H///YebN2+iXr16UCgUUCgUuHr1Kt599114enqWuB8bUkRERESAq6srEhMTC61LTEyEjY1Nib2kAEClUhl7RbF3FBEREVUmk318b8SIEcWOgzBixAgEBweXuJ9KpYJKparseEREREQmrWPHjvj9998Lrdu9ezc6duwoUSIiIiKiwiQtSmVkZODixYvG1zExMYiOjoa9vT3q1asHBweHQtubmZnB1dUVzZo1q+qoREREMBgMyM3NlToGVRClUlnqFMWm5mHtpsmTJ+P69etYtWoVAODVV1/FggUL8MEHH2DUqFH4+++/sWnTJvz2229SXQIREdVyer0eeXl5UsegCmBmZga5XP7Yx5G0KBUZGYmnnnrK+HrSpEkAgJEjRyI0NFSiVEREREXl5uYiJiYGBoNB6ihUQWQyGRo0aAClUil1lDJ5WLvpxo0biI2NNb7foEED/Pbbb3jnnXfw3XffoW7duli2bBl69OhR5dmJiKh2E0URCQkJSE1NlToKVSBbW1u4uro+1sQwgnh3nt8aSqvVQqPRIC0tjWMiEBFRuYiiiNjYWOTl5cHd3b1a9a6h4hkMBsTHx8PMzAz16tUr0phi++Ee3gsiInpcN27cQGpqKpydnWFhYVGtZ7elgrZxVlYWbt68CVtbW7i5uRXZpqztB5MdU4qIiMhU5OfnIysrC+7u7rCwsJA6DlUQJycnxMfHIz8/H2ZmZlLHISIiqpH0er2xIPXgED1Ufd2dNOXmzZtwdnYu96N8/KiXiIjoIfR6PQBUm8e8qGzu/jzv/nyJiIio4t0dQ4of7NU8d3+mjzNOGItSREREZcSu5jULf55ERERVh793a56K+JmyKPWYdPl6pGZxJiYiIiKi8riZnoMaPsQpERERlYBFqceQlZuP0aGRCFwRjvQcTmtJREQ1n6enJ+bPny91DKohIq+k4Llv/8Xify5LHYWIiKhKsC1VGItSjyFRq8PpG1ocv5aGMSsjkZPHMSmIiMg0CIJQ6jJjxoxyHTciIgLjxo2r2LBUa52K1yI1Kw9zd57F9mPxUschIiIyYluqanD2vcfQwNESq0b5YciPhxEWk4LX1x7B4uHtoVSw1kdERNK6ceOG8fuNGzdi2rRpOHfunHGdlZWV8XtRFKHX66FQPLxZ4OTkVLFBqVYb2ckTV29lYcWBGLy36RjcNGr4etpLHYuIiIhtqSrC6sljal1Hg+VBvlApZPj77E1M2hQNvYHjIhARkbRcXV2Ni0ajgSAIxtdnz56FtbU1/vjjD7Rv3x4qlQr79+/HpUuX0LdvX7i4uMDKygq+vr7466+/Ch33wS7ngiBg2bJl6N+/PywsLNCkSRNs3769iq+WqrNPerdAj1YuyNUbMHZVJC4lZUgdiYiIiG2pKsKiVAXwa2CPxSPaw0wuYMfxG5iy7SQH7CQiqsFEUURWbr4kS0X+fvnoo4/wxRdf4MyZM2jbti0yMjLw/PPPY8+ePTh69Ch69uyJPn36IDY2ttTjzJw5E4MGDcLx48fx/PPPY9iwYUhJSamwnFSzyWUC5g/2gbeHLVKz8hAcEoHkDJ3UsYiIqBKxLVVYbW5L8fG9CvJUM2fMH+yDieuPYH14LGzUCnzUqzmnvSQiqoGy8/RoOW2XJOc+/WkPWCgr5tf3p59+imeffdb42t7eHl5eXsbXn332GbZu3Yrt27djwoQJJR4nKCgIQ4YMAQDMnj0b33//PcLDw9GzZ88KyUk1n7lSjmUjO2DADwcRm5KFMSsjsWHcE1CbyaWORkRElYBtqcJqc1uKPaUqUO+2bpgzoA0AYMm/l/HDvksSJyIiIipZhw4dCr3OyMjAe++9hxYtWsDW1hZWVlY4c+bMQz/da9u2rfF7S0tL2NjY4ObNm5WSmWouRysVQoJ9YWthhui4VLy9gUMiEBGRaWNb6vGxp1QFG+xbD+k5+Zj12xl8tescrNUKBHb0lDoWERFVIHMzOU5/2kOyc1cUS0vLQq/fe+897N69G/PmzUPjxo1hbm6Ol156Cbm5uaUex8zMrNBrQRBgMBgqLCfVHo2crPDjiA4YviwMO08lYPbvZzD1hZZSxyIiogrGtlRhtbktxaJUJRjzZENoc/Lx/Z4LmPbLKVirFejvU1fqWEREVEEEQaiwbt+m5MCBAwgKCkL//v0BFHzad+XKFWlDUa3j18Ae8wZ54c31R7F8fww87MwR1LmB1LGIiKgCsS1Fd/HxvUryTkATBHXyBAC8t/k4dp1KkDYQERHRQzRp0gRbtmxBdHQ0jh07hqFDh9aaT+nItLzo5Y4PejYDAHy64zR2n06UOBEREdHDsS316FiUqiSCIGDaCy0xsF1d6A0iJq47igMXk6WORUREVKJvvvkGdnZ26NSpE/r06YMePXqgXbt2UseiWuq1bo0wxK8eDCIwcf0RHItLlToSERFRqdiWenSCWJHzIZogrVYLjUaDtLQ02NjYVPn58/UGTFh3FDtPJcBCKceaMf5oV8+uynMQEVH55eTkICYmBg0aNIBarZY6DlWQ0n6uUrcfTImU9yJfb8DolZH453wSHK2U2Pp6Z3jYW1RpBiIiejxsR9VcFdGWYk+pSqaQy/DdEG882cQRWbl6BK0Ix5kbWqljEREREZk8hVyGhcPaoaWbDZIzchEcGoG0rDypYxEREVEFYVGqCqgUciwZ0R7t69tBm5OPEcvDEZOcKXUsIiIiIpNnpVJgRZAv3DRqXLyZgXGrI6HL10sdi4iIiCoAi1JVxEJZ0KBq4WaD5Awdhi8LQ3xqttSxiIiIiEyeq0aNFUG+sFIpEBaTgg9/Oo4aPgIFERFRrcCiVBXSmJth9Wg/NHS0xPXUbAxfHobkDJ3UsYiIiIhMXgs3Gywa3g4KmYBt0fH4Zvd5qSMRERHRY2JRqoo5Wqmweow/3DVqXE7KRODycKRlc2wEIiIiood5sokTZvdvAwD4398XsSkiTuJERERE9DhYlJJAHVtzrBnjD0crJU7f0GJ0aASyczk2AhEREdHDDPL1wMSnGwMAJm89gX/PJ0mciIiIiMqLRSmJNHSywqpR/rBWKxB59TbGr4lCbr5B6lhEREREJm/Ss03R36cO9AYRr689wpmNiYiIqikWpSTU0t0GocG+MDeT49/zSXh741Hk61mYIiIiIiqNIAj4YmAbPNHQHhm6fASHRCAhLUfqWERERPSIWJSSWPv69vgxsD2Uchl+P5GAyVtOwGDgbDJEREREpVEp5FgyvAMaO1shQZuD4NAIZOjypY5FREREj4BFKRPwZBMnfD/EGzIB2Bx1DbN+O8NpjomISHLdu3fH22+/bXzt6emJ+fPnl7qPIAjYtm3bY5+7oo5DNZvGwgwhQb5wtFLizA0t3lh7BHnsdU5ERCaCbamHY1HKRPRs7YYvX/ICAKw4EIPv9lyQOBEREVVnffr0Qc+ePYt977///oMgCDh+/PgjHTMiIgLjxo2riHhGM2bMgLe3d5H1N27cQK9evSr0XFQzedhbYPnIguEQ/jmfhGm/nOSHe0RE9NjYlqoaLEqZkJfa18X0Pi0BAPP/uoDl+2MkTkRERNXV6NGjsXv3bly7dq3IeyEhIejQoQPatm37SMd0cnKChYVFRUUslaurK1QqVZWci6o/Lw9bfD/EBzIBWB8eh0X/XJI6EhERVXNsS1UNFqVMTHDnBpj0bFMAwGc7TmNTZJzEiYiIqDp64YUX4OTkhNDQ0ELrMzIysHnzZvTr1w9DhgxBnTp1YGFhgTZt2mD9+vWlHvPBLucXLlxA165doVar0bJlS+zevbvIPh9++CGaNm0KCwsLNGzYEFOnTkVeXh4AIDQ0FDNnzsSxY8cgCAIEQTDmfbDL+YkTJ/D000/D3NwcDg4OGDduHDIyMozvBwUFoV+/fpg3bx7c3Nzg4OCAN954w3guqvmebemC6X1aAQC+3HkOv0RflzgRERFVZ2xLVU1bSlGpR6dymfh0Y6Tn5GHpfzH46OfjsFIp8HwbN6ljERHRXaII5GVJc24zC0AQHrqZQqFAYGAgQkND8cknn0C4s8/mzZuh1+sxfPhwbN68GR9++CFsbGzw22+/YcSIEWjUqBH8/PweenyDwYABAwbAxcUFYWFhSEtLKzRmwl3W1tYIDQ2Fu7s7Tpw4gbFjx8La2hoffPABBg8ejJMnT2Lnzp3466+/AAAajabIMTIzM9GjRw907NgRERERuHnzJsaMGYMJEyYUaiju3bsXbm5u2Lt3Ly5evIjBgwfD29sbY8eOfej1UM0wspMnYlOysHx/DN7ffBxuGnP4NbCXOhYRET2IbSm2pe5gUcoECYKAj59vAW12PjZGxuGtDUdhqVKgW1MnqaMRERFQ0Iia7S7NuT+OB5SWZdp01KhR+Oqrr/DPP/+ge/fuAAq6mw8cOBD169fHe++9Z9x24sSJ2LVrFzZt2lSmhtRff/2Fs2fPYteuXXB3L7gXs2fPLjJ2wZQpU4zfe3p64r333sOGDRvwwQcfwNzcHFZWVlAoFHB1dS3xXOvWrUNOTg5WrVoFS8uCa1+wYAH69OmDuXPnwsXFBQBgZ2eHBQsWQC6Xo3nz5ujduzf27NnDolQt88nzLXD9djZ2nkrA2FWR2PJ6JzRyspI6FhER3Y9tKbal7uDjeyZKEATMHtAGvdu6IU8vYvzqSERcSZE6FhERVSPNmzdHp06dsGLFCgDAxYsX8d9//2H06NHQ6/X47LPP0KZNG9jb28PKygq7du1CbGxsmY595swZeHh4GBtRANCxY8ci223cuBGdO3eGq6srrKysMGXKlDKf4/5zeXl5GRtRANC5c2cYDAacO3fOuK5Vq1aQy+XG125ubrh58+YjnYuqP5lMwPxXvOFTzxZp2XkICglHcoZO6lhERFQNsS1V+W0p9pQyYXKZgG8HeSNTl49955IwKiQC68c9gdZ1inbHIyKiKmRmUfApm1TnfgSjR4/GxIkTsXDhQoSEhKBRo0bo1q0b5s6di++++w7z589HmzZtYGlpibfffhu5ubkVFvXQoUMYNmwYZs6ciR49ekCj0WDDhg34+uuvK+wc9zMzMyv0WhAEGAyGSjkXmTa1mRxLAztgwA8HEZuShTErI7F+7BMwV8ofvjMREVU+tqXKpDa0pdhTysQpFTIsGtYefp72SNflI3BFOC7ezHj4jkREVHkEoaDbtxRLGcZAuN+gQYMgk8mwbt06rFq1CqNGjYIgCDhw4AD69u2L4cOHw8vLCw0bNsT58+fLfNwWLVogLi4ON27cMK47fPhwoW0OHjyI+vXr45NPPkGHDh3QpEkTXL16tdA2SqUSer3+oec6duwYMjMzjesOHDgAmUyGZs2alTkz1S6OViqEBvvC1sIM0XGpeHvjUegNotSxiIgIYFsKbEvdxaJUNWCulGNZUAe0rmODlMxcjFgehmu3JRoUjoiIqhUrKysMHjwYkydPxo0bNxAUFAQAaNKkCXbv3o2DBw/izJkzGD9+PBITE8t83ICAADRt2hQjR47EsWPH8N9//+GTTz4ptE2TJk0QGxuLDRs24NKlS/j++++xdevWQtt4enoiJiYG0dHRSE5Ohk5X9DGrYcOGQa1WY+TIkTh58iT27t2LiRMnYsSIEcYxEIiK09DJCksDO0Apl2HXqUR8/tsZqSMREVE1w7ZU5WJRqpqwUZthZbAfGjlZ4kZaDoYvC0NSOsdHICKihxs9ejRu376NHj16GMctmDJlCtq1a4cePXqge/fucHV1Rb9+/cp8TJlMhq1btyI7Oxt+fn4YM2YMPv/880LbvPjii3jnnXcwYcIEeHt74+DBg5g6dWqhbQYOHIiePXviqaeegpOTU7FTKVtYWGDXrl1ISUmBr68vXnrpJTzzzDNYsGDBo98MqnV8Pe3x9SAvAMCKAzEIORAjcSIiIqpu2JaqPIIoijW6H7NWq4VGo0FaWhpsbGykjvPYEtJy8NLig7h2OxvNXa2xcVxHaCzMHr4jERGVW05ODmJiYtCgQQOo1Wqp41AFKe3nWtPaD4+jptyLRfsuYe7OsxAEYMnw9niuVcmzFBERUcVhO6rmqoi2FHtKVTOuGjXWjPaHk7UKZxPSERQajkxdvtSxiIiIiEzaq90aYqh/PYgi8OaGo4iOS5U6EhERUa3HolQ15OloidWj/aAxN8PR2FSMWx2JnLzSBzYjIiIiqs0EQcCnL7ZC92ZOyMkzYMzKCMSlcIxOIiIiKbEoVU01d7XBylF+sFTKceDiLby5/ijy9Zz2moiIiKgkCrkMC4a2Q0s3GyRn5CIoJBxpWXlSxyIiIqq1JC1K/fvvv+jTpw/c3d0hCAK2bdtW6P0ZM2agefPmsLS0hJ2dHQICAhAWFiZNWBPk7WGLpSM7QKmQ4c/Tifjgp+MwcKpjIiIiohJZqRQICfaFm0aNS0mZGLc6Erp89jgnIiKSgqRFqczMTHh5eWHhwoXFvt+0aVMsWLAAJ06cwP79++Hp6YnnnnsOSUlJVZzUdHVq5IiFQ9tBLhOw5eh1zPz1FGr42PVEREREj8XFRo2QYF9YqxQIi0nBBz8dZ/uJiIhIApIWpXr16oVZs2ahf//+xb4/dOhQBAQEoGHDhmjVqhW++eYbaLVaHD9+vIqTmrZnW7rgm0FeEARg5aGr+PrP81JHIiKqkfiP1pqFP8/arbmrDRYNbw+FTMAv0fFsPxERVTKDgcPN1DQV8TNVVECOKpGbm4sff/wRGo0GXl5eJW6n0+mg0+mMr7VabVXEk1xf7zrQ5uRj6raTWLD3IqzVCozv1kjqWERENYKZmRkEQUBSUhKcnJwgCILUkegxiaKIpKQkCIIAMzMzqeOQRLo0ccTsAW3wwU/HsWDvRdS1M8crfvWkjkVEVKMolUrIZDLEx8fDyckJSqWSbalqThRF5ObmIikpCTKZDEqlstzHMvmi1I4dO/DKK68gKysLbm5u2L17NxwdHUvcfs6cOZg5c2YVJjQdI56oj/ScPHy58xzm/HEWNuZmGMKGFRHRY5PL5ahbty6uXbuGK1euSB2HKoggCKhbty7kcrnUUUhCgzp44FpKFr7/+yI+2XYS7rbm6NrUSepYREQ1hkwmQ4MGDXDjxg3Ex8dLHYcqkIWFBerVqweZrPwP4QmiifRdFwQBW7duRb9+/Qqtz8zMxI0bN5CcnIylS5fi77//RlhYGJydnYs9TnE9pTw8PJCWlgYbG5vKvASTMXfnWSzadwmCAHz/ig/6eLlLHYmIqEbQ6/XIy+NMXTWFmZlZiQUprVYLjUZTq9oPJakN90IURby76Ri2HL0OK5UCm8Z3REv3mnmtRERSEUUR+fn50Os5uURNIJfLoVAoSuz1Vtb2g8n3lLK0tETjxo3RuHFjPPHEE2jSpAmWL1+OyZMnF7u9SqWCSqWq4pSm5YMezaDNzsPasFi8szEalio5nm7uInUsIqJqTy6Xs1cNUQ0kCAK+GNgW8WnZOHw5BaNCI7D1jU5w05hLHY2IqMa4+8g8H5un+0k60Hl5GAyGQj2hqChBEPBZ39bo6+2OfIOI19YcweHLt6SORURERBVg4cKF8PT0hFqthr+/P8LDw0vdfv78+WjWrBnMzc3h4eGBd955Bzk5OVWUtvpQKmRYMrwDGjtbIUGbg+CQCKTnsGckERFRZZK0KJWRkYHo6GhER0cDAGJiYhAdHY3Y2FhkZmbi448/xuHDh3H16lVERUVh1KhRuH79Ol5++WUpY1cLMpmAeS97IaCFM3T5BoxZGYnj11KljkVERESPYePGjZg0aRKmT5+OI0eOwMvLCz169MDNmzeL3X7dunX46KOPMH36dJw5cwbLly/Hxo0b8fHHH1dx8upBY2GGkCBfOFqpcDYhHW+sO4o8PWeLIiIiqiySFqUiIyPh4+MDHx8fAMCkSZPg4+ODadOmQS6X4+zZsxg4cCCaNm2KPn364NatW/jvv//QqlUrKWNXG2ZyGRYMbYeODR2QocvHyBXhuJCYLnUsIiIiKqdvvvkGY8eORXBwMFq2bInFixfDwsICK1asKHb7gwcPonPnzhg6dCg8PT3x3HPPYciQIQ/tXVWbedhbYEVQB5ibyfHv+SRM3XYSJjIEKxERUY0jaVGqe/fuEEWxyBIaGgq1Wo0tW7bg+vXr0Ol0iI+Pxy+//AJfX18pI1c7ajM5lo7sAK+6GtzOysOwZWGIvZUldSwiIiJ6RLm5uYiKikJAQIBxnUwmQ0BAAA4dOlTsPp06dUJUVJSxCHX58mX8/vvveP7550s8j06ng1arLbTUNm3r2uJ/Q3wgE4ANEXH4Yd8lqSMRERHVSNVuTCl6dFYqBUKD/dDMxRo303UYvjwMiVqOJUFERFSdJCcnQ6/Xw8Wl8OQlLi4uSEhIKHafoUOH4tNPP0WXLl1gZmaGRo0aoXv37qU+vjdnzhxoNBrj4uHhUaHXUV0EtHTBjBcLeud/tescfom+LnEiIiKimodFqVrCzlKJ1aP9UM/eArEpWRixPAy3M3OljkVERESVaN++fZg9ezZ++OEHHDlyBFu2bMFvv/2Gzz77rMR9Jk+ejLS0NOMSFxdXhYlNS2BHT4zp0gAA8P7m4wjjxDFEREQVikWpWsTZRo21Y/zhYqPC+cQMjAwJ56wyRERE1YSjoyPkcjkSExMLrU9MTISrq2ux+0ydOhUjRozAmDFj0KZNG/Tv3x+zZ8/GnDlzYDAUP4C3SqWCjY1NoaU2+/j5FujV2hW5egPGrY7CxZsZUkciIiKqMViUqmU87C2wZrQ/7CzMcPxaGsasjEROnl7qWERERPQQSqUS7du3x549e4zrDAYD9uzZg44dOxa7T1ZWFmSyws09uVwOABy8u4xkMgHfDvaGTz1bpGXnITg0HEnpOqljERER1QgsStVCTVyssWqUP6xUCoTFpOCNtUc43TEREVE1MGnSJCxduhQrV67EmTNn8NprryEzMxPBwcEAgMDAQEyePNm4fZ8+fbBo0SJs2LABMTEx2L17N6ZOnYo+ffoYi1P0cGozOZYFdkB9BwvEpWRjzKpIZOfyQz0iIqLHpZA6AEmjTV0Nlo/sgMAV4dhz9iYmbTqG+YO9IZcJUkcjIiKiEgwePBhJSUmYNm0aEhIS4O3tjZ07dxoHP4+NjS3UM2rKlCkQBAFTpkzB9evX4eTkhD59+uDzzz+X6hKqLQcrFUKCfDFg0UEci0vFWxuOYtHw9mw7ERERPQZBrOF9t7VaLTQaDdLS0mr9mAjF2Xv2JsauikS+QcRQ/3r4vF9rCAIbV0REVLux/XAP70VhkVdSMHRZGHLzDQju7InpfVpJHYmIiMjklLX9wMf3armnmjvj28HeEARgXVgs5u48J3UkIiIiIpPVwdMeX7/sBQAIOXAFK/bHSJyIiIio+mJRitDHyx1z+rcBACz+5xIW7r0ocSIiIiIi09XHyx0f9WoOAPjst9PYdSpB4kRERETVE4tSBAB4xa8ePnm+BQDgq13nsPrQFWkDEREREZmw8V0bYqh/PYgi8NaGo4iOS5U6EhERUbXDohQZje3aEBOfbgwAmPrLKWw9ek3iRERERESmSRAEfPpiKzzVzAk5eQaMDo1A7K0sqWMRERFVKyxKUSGTnm2KoE6eAID3Nh/Hn+yOTkRERFQshVyGBUPboZW7DW5l5iIoNBypWblSxyIiIqo2WJSiQgRBwLQXWmJAuzrQG0RMWHcUBy4mSx2LiIiIyCRZqhRYEeQLd40al5MyMW51FHT5eqljERERVQssSlERMpmALwe2RY9WLsjVGzB2VSSOxt6WOhYRERGRSXKxUSMk2A/WKgXCY1Lw/ubjMBhEqWMRERGZPBalqFgKuQzfD/HBk00ckZWrR1BIBM7c0Eodi4iIiMgkNXO1xqLh7aGQCdh+LB5f7z4ndSQiIiKTx6IUlUilkGPJiPZoV88Wadl5GLE8HFeSM6WORURERGSSujRxxJwBbQAAC/dewvrwWIkTERERmTYWpahUFkoFQoL80NzVGskZOgxbFoYbadlSxyIiIiIySS938MCbzzQBAEzZdhL/nE+SOBEREZHpYlGKHkpjYYbVo/3RwNES11OzMXxZGG5l6KSORURERGSS3gloggE+BZPGvL4mCqfjOQQCERFRcViUojJxslZhzRh/uGvUuJSUicAV4dDm5Ekdi4iIiMjkCIKALwa2RceGDsjM1WNUaAR7mhMRERWDRSkqszq25lg9xh8OlkqcitdidGgEsnM55TERERHRg5QKGRaPaI8mzlZI0OYgOCQC6fxAj4iIqBAWpeiRNHKywqrRfrBWKxBx5TZeXROF3HyD1LGIiIiITI7G3Awhwb5wslbhbEI6Xl97BHl6tpuIiIjuYlGKHlkrdw1CgnxhbibHP+eT8M7GaOgNotSxiIiIiExOXTsLLB/ZAeZmcvx3IRlTtp6EKLLdREREBLAoReXUwdMeS0a0h5lcwG8nbmDyluNsYBEREREVo21dWywY6gOZAGyMjMMP+y5JHYmIiMgksChF5da1qRO+f6WggbUp8hpm/XaGhSkiIiKiYjzTwgUzX2wFAPhq1zn8En1d4kRERETSY1GKHkuvNm6YO7AtAGD5/hh8v+eixImIiIiITNOIjp4Y+2QDAMD7m4/j8OVbEiciIiKSFotS9Nhe7uCBaS+0BAB8+9d5rNgfI3EiIiIiItM0uVcLPN/GFbl6A8atisTFm+lSRyIiIpIMi1JUIUZ1aYB3ApoCAD7dcRqbI+MkTkRERERkemQyAd8M8ka7erbQ5uQjKCQCSek6qWMRERFJgkUpqjBvPtMYY7oUdEn/8Ofj+OPEDYkTEREREZketZkcSwM7oL6DBa7dzsaYlRHIys2XOhYREVGVY1GKKowgCPikdwsM7uABgwi8ueEo/jmfJHUsIiIiIpPjYKVCaLAf7CzMcOxaGt7aEA29gRPGEBFR7cKiFFUoQRAwe0Ab9G7jhjy9iPGrIxF5JUXqWEREREQmp4GjJZYGdoBSIcPu04n4bMdpqSMRERFVKRalqMLJZQK+HeyNbk2dkJNnQHBoBE7Fp0kdi4iIiMjkdPC0x7eDvAEAoQevcMIYIiKqVViUokqhVMiweHh7+HraIT0nH4HLw3EpKUPqWEREREQmp3dbN0zu1RwA8Nlvp7HzZILEiYiIiKoGi1JUacyVciwP8kUrdxvcyszFiGVhuJ6aLXUsIiIiIpMzrmtDDPOvB1EE3tpwFEdjb0sdiYiIqNKxKEWVykZthlWj/NDIyRLxaTkYviyM0x4TERERPUAQBMx8sRWebu4MXb4BY1ZGIvZWltSxiIiIKhWLUlTpHKxUWDPGH3VszRGTnIkRy8OQlpUndSwiIiIik6KQy/C/IT7GXuZBoeFIzcqVOhYREVGlYVGKqoSbxhxrx/jD0UqFswnpCA4NR6YuX+pYRERERCbFUqXAiiBfuGvUuJyUiXGropCTp5c6FhERUaVgUYqqjKejJdaM8YPG3AxHYlMxfnUUdPlsZBERERHdz8VGjZBgP1irFAi/koL3fzoOg0GUOhYREVGFY1GKqlRzVxuEBvvCQinH/ovJeHP9UeTrDVLHIiIiIjIpzVytsXhEeyhkAn49Fo95f56TOhIREVGFY1GKqpxPPTssC+wApUKGXacS8cHP/PSPiIiI6EGdGzvii4FtAQA/7LuEdWGxEiciIiKqWJIWpf7991/06dMH7u7uEAQB27ZtM76Xl5eHDz/8EG3atIGlpSXc3d0RGBiI+Ph46QJThenU2BELhvhALhOw5ch1fLrjNESRhSkiIiKi+73Uvi7eeqYJAGDqLyex79xNiRMRERFVHEmLUpmZmfDy8sLChQuLvJeVlYUjR45g6tSpOHLkCLZs2YJz587hxRdflCApVYbnWrli3ssFn/6FHryCb3eflzgRERERkel5O6AJBrSrA71BxBtrj+BUfJrUkYiIiCqEQsqT9+rVC7169Sr2PY1Gg927dxdat2DBAvj5+SE2Nhb16tWriohUyfr71EVGTj6m/nIK3/99EdZqM4zt2lDqWEREREQmQxAEfDGgLRLScnDw0i2MCo3A1tc7w93WXOpoREREj6VajSmVlpYGQRBga2srdRSqQCM6euL9Hs0AAJ//fgbrwzleAhEREdH9lAoZFg1vj6YuVkjU6jAqNALpOXlSxyIiInos1aYolZOTgw8//BBDhgyBjY1NidvpdDpotdpCC5m+17s3wvhuBT2kPt56Ar8e49hhRERERPfTmJthRZAvnKxVOJuQjtfXHkEeZzEmIqJqrFoUpfLy8jBo0CCIoohFixaVuu2cOXOg0WiMi4eHRxWlpMchCAI+6tkcQ/3rQRSBdzZGY+9ZDuRJREREdL+6dhZYMdIX5mZy/HchGZ9sPcHJYoiIqNoy+aLU3YLU1atXsXv37lJ7SQHA5MmTkZaWZlzi4uKqKCk9LkEQ8Fnf1njRyx35BhGvrolC2OVbUsciIiIiMilt6mqwYKgPZAKwKfIaFu69KHUkIiKicjHpotTdgtSFCxfw119/wcHB4aH7qFQq2NjYFFqo+pDLBHw9yAvPNHeGLt+A0SsjceIaZ5ghIiIiut8zLVww88VWAIB5f57HtqPXJU5ERET06CQtSmVkZCA6OhrR0dEAgJiYGERHRyM2NhZ5eXl46aWXEBkZibVr10Kv1yMhIQEJCQnIzc2VMjZVMjO5DAuHtcMTDe2RoctH4IowXEhMlzoWERERkUkZ0dET4+7MWvz+T8dw6BJ7mBMRUfUiaVEqMjISPj4+8PHxAQBMmjQJPj4+mDZtGq5fv47t27fj2rVr8Pb2hpubm3E5ePCglLGpCqjN5Fg20hdedTW4nZWH4cvDEJeSJXUsIiIiIpPyUc/meL6NK/L0IsavjsTFm/wgj4iIqg9BrOEjI2q1Wmg0GqSlpfFRvmrodmYuBi05hAs3M1DP3gI/vdoRzjZqqWMREVENx/bDPbwXpi8nT4+hSw/jSGwq6tqZY+vrneFkrZI6FhER1WJlbT+Y9JhSRHaWSqwZ44969haITcnC8OVhuJ3JxzeJiIiI7rrbw9zTwQLXbmdj9MoIZOXmSx2LiIjooViUIpPnYqPG2jH+cLFR4XxiBoJCwpGhY0OLiIiI6C57SyVCgv1gZ2GG49fS8Ob6aOgNNfqBCCIiqgFYlKJqwcPeAmtG+8POwgzHrqVhzMoI5OTppY5FREREZDIaOFpi2cgOUCpk+OtMIj7bcRo1fKQOIiKq5liUomqjiYs1Vo7yg5VKgcOXUzBh3RHk6Q1SxyIiIiIyGe3r2+PbQd4AgNCDV7B8f4y0gYiIiErBohRVK23r2mLZyA5QKWT468xNvLf5GAzsmk5ERLXIwoUL4enpCbVaDX9/f4SHh5e6fWpqKt544w24ublBpVKhadOm+P3336soLUmhd1s3fPx8cwDA57+fwc6TNyROREREVDwWpajaeaKhAxYNbweFTMAv0fGY+stJdk0nIqJaYePGjZg0aRKmT5+OI0eOwMvLCz169MDNmzeL3T43NxfPPvssrly5gp9++gnnzp3D0qVLUadOnSpOTlVt7JMNMfyJehBF4K0N0TgSe1vqSEREREWwKEXV0tPNXfDtYG8IArA2LBZf7jondSQiIqJK980332Ds2LEIDg5Gy5YtsXjxYlhYWGDFihXFbr9ixQqkpKRg27Zt6Ny5Mzw9PdGtWzd4eXlVcXKqaoIgYEafVni6uTN0+QaMXRmJq7cypY5FRERUCItSVG318XLH7P5tAACL9l3CD/suSpyIiIio8uTm5iIqKgoBAQHGdTKZDAEBATh06FCx+2zfvh0dO3bEG2+8ARcXF7Ru3RqzZ8+GXl/yZCE6nQ5arbbQQtWTQi7D/4b4oHUdG9zKzEVwSARuZ+ZKHYuIiMiIRSmq1ob41TOOmfDlznNYffiqxImIiIgqR3JyMvR6PVxcXAqtd3FxQUJCQrH7XL58GT/99BP0ej1+//13TJ06FV9//TVmzZpV4nnmzJkDjUZjXDw8PCr0OqhqWaoUWDHSF3VszXE5ORPjVkdyBmMiIjIZLEpRtTeuayNMeKoxAGDaLyex7eh1iRMRERGZBoPBAGdnZ/z4449o3749Bg8ejE8++QSLFy8ucZ/JkycjLS3NuMTFxVVhYqoMzjZqhAT7wlqtQMSV23j/p+OcKIaIiEwCi1JUI7z7XFOM7Fgfogi8u/kYdp9OlDoSERFRhXJ0dIRcLkdiYuHfcYmJiXB1dS12Hzc3NzRt2hRyudy4rkWLFkhISEBubvGPcalUKtjY2BRaqPpr6mKNJcPbQyET8OuxeHz1J8fjJCIi6bEoRTWCIAiY3qcVBvjUgd4g4o11R3DwYrLUsYiIiAAAISEhyMrKeqxjKJVKtG/fHnv27DGuMxgM2LNnDzp27FjsPp07d8bFixdhMBiM686fPw83NzcolcrHykPVT6fGjvhiYFsABeNxrguLlTgRERHVdixKUY0hkwn48qW2eK6lC3LzDRizKhJHOf0xERGZgI8++giurq4YPXo0Dh48WO7jTJo0CUuXLsXKlStx5swZvPbaa8jMzERwcDAAIDAwEJMnTzZu/9prryElJQVvvfUWzp8/j99++w2zZ8/GG2+88djXRNXTS+3r4u2AJgCAqb+cxN5zNyVOREREtRmLUlSjKOQyfD/EB50bOyArV4+gkAicS0iXOhYREdVy169fx8qVK5GcnIzu3bujefPmmDt3bokDlJdk8ODBmDdvHqZNmwZvb29ER0dj586dxsHPY2NjcePGDeP2Hh4e2LVrFyIiItC2bVu8+eabeOutt/DRRx9V6PVR9fLWM00wsF1d6A0iJqw9glPxaVJHIiKiWkoQRbFGj3Ko1Wqh0WiQlpbGMRFqkUxdPoYvD8PR2FQ4WauweXxHeDpaSh2LiIiqicpsPyQmJmLNmjVYuXIlzp49i549e2L06NHo06cPZDLT+7yQbamaKTffgKCQcBy8dAsuNipsfb0z3G3NpY5FREQ1RFnbD6bX8iGqAJYqBUKD/NDc1RpJ6ToMWxaGG2nZUsciIiKCi4sLunTpgo4dO0Imk+HEiRMYOXIkGjVqhH379kkdj2oJpUKGRcPbo6mLFRK1OgSHRECbkyd1LCIiqmVYlKIaS2NhhlWj/eDpYIHrqdkYviwMtzJ0UsciIqJaKjExEfPmzUOrVq3QvXt3aLVa7NixAzExMbh+/ToGDRqEkSNHSh2TahGNuRlCgv3gZK3CucR0vLH2CPL0hofvSEREVEFYlKIazdlajTVj/OGmUeNSUiZGhoTzU0AiIqpyffr0gYeHB0JDQzF27Fhcv34d69evR0BAAADA0tIS7777LuLi4iROSrVNHVtzhAT5wkIpx38XkvHxlhOo4aN7EBGRCWFRimq8unYWWD3aHw6WSpy8rsWY0Ehk5+qljkVERLWIs7Mz/vnnH5w8eRJvv/027O3ti2zj5OSEmJgYCdJRbde6jgYLhvpAJgCbo65hwd8XpY5ERES1BItSVCs0drbCylF+sFYrEH4lBa+tjUJuPrunExFR1ejWrRvatWtXZH1ubi5WrVoFABAEAfXr16/qaEQAgKebu2Bm39YAgK93n8fWo9ckTkRERLUBi1JUa7Suo0FIkC/UZjLsO5eEdzZGQ29g93QiIqp8wcHBSEtLK7I+PT0dwcHBEiQiKmrEE/UxvmtDAMAHPx3HwUvJEiciIqKajkUpqlU6eNpjyYgOMJML+O3EDY6bQEREVUIURQiCUGT9tWvXoNFoJEhEVLwPezZH7zZuyNOLGL86ChcS06WORERENZhC6gBEVa1bUyd894oPJqw7go2RcbBWK/BJ7xbF/mOBiIjocfj4+EAQBAiCgGeeeQYKxb2ml16vR0xMDHr27ClhQqLCZDIBXw/yQoI2B1FXbyMoJAJb3+gEZ2u11NGIiKgGYlGKaqXn27jhi4Ft8cFPx7FsfwxszM3w5jNNpI5FREQ1TL9+/QAA0dHR6NGjB6ysrIzvKZVKeHp6YuDAgRKlIyqe2kyOpYEdMHDRQcQkZ2J0aCQ2jn8CFkr+04GIiCoWf7NQrTWogwcycvLx6Y7T+Gb3eVirFQju3EDqWEREVINMnz4dAODp6YnBgwdDrWZvE6oe7C2VCAnyRf8fDuDE9TS8uf4olozoALmMPcuJiKjicEwpqtVGdWmAtwMKekjN/PU0foriTDNERFTxRo4cyYIUVTuejpZYNrIDlAoZ/jpzE5/+eopjcRIRUYViUYpqvbeeaYJRd3pIffDTMew8eUPiREREVBPY29sjOblg9jI7OzvY29uXuBCZqvb17TF/sDcEAVh56CqW74+ROhIREdUgfHyPaj1BEDD1hRbI0OVhU+Q1vLk+GsuDFHiyiZPU0YiIqBr79ttvYW1tbfyeE2pQdfV8Gzd83KsFPv/9DD7//Qzq2JqjVxs3qWMREVENIIg1vA+uVquFRqNBWloabGxspI5DJkxvEDFx/RH8fiIB5mZyrBnjh/b1+ek1EVFtxPbDPbwXBACiKGLaL6ew+vBVqBQyrBv7BNrXt5M6FhERmaiyth/4+B7RHXKZgG8He6NrUydk5+kRFBKB0/FaqWMREVENEBoaWuz6/Px8TJ48uWrDEJWDIAiY3qclnmnuDF2+AWNXReJKcqbUsYiIqJpjUYroPiqFHEuGt4evpx3Sc/IRuCIMl5MypI5FRETV3JtvvomXX34Zt2/fNq47d+4c/P39sX79egmTEZWdQi7D/4b6oE0dDVIycxEcGoHbmblSxyIiomqsXEWpuLg4XLt2b5ay8PBwvP322/jxxx8rLBiRVMyVciwP8kUrdxskZ+Ri+LIwXE/NljoWERFVY0ePHsW1a9fQpk0b7N69GwsXLkS7du3QvHlzHDt2TOp4RGVmoVRg+cgOqGNrjpjkTIxdFYmcPL3UsYiIqJoqV1Fq6NCh2Lt3LwAgISEBzz77LMLDw/HJJ5/g008/rdCARFKwUZth5Sg/NHSyRHxaDkYsC0NSuk7qWEREVE01atQIBw4cwIABA9CzZ0+88847WLZsGdauXQuNRiN1PKJH4myjRkiwL6zVCkRevY33Nh+DwVCjh6klIqJKUq6i1MmTJ+Hn5wcA2LRpE1q3bo2DBw9i7dq1JY6ZQFTdOFqpsGa0P+rYmuNyciYCV4QjLStP6lhERFRN/fbbb9iwYQM6duwIW1tbLF++HPHx8VLHIiqXpi7WWDK8PczkAnYcv4Evd52TOhIREVVD5SpK5eXlQaVSAQD++usvvPjiiwCA5s2b48aNGxWXjkhi7rbmWDPGH45WKpy5oUVwaDiycvOljkVERNXM+PHj8fLLL+PDDz/Ef//9h+PHj0OpVKJNmzbYtGmT1PGIyqVTY0d8MaAtAGDxP5ewNuyqxImIiKi6KVdRqlWrVli8eDH+++8/7N69Gz179gQAxMfHw8HBoUIDEkmtgaMlVo/2g41agSOxqRi/Ogq6fI6dQEREZXfgwAGEhYXh3XffhSAIcHV1xe+//45PP/0Uo0aNkjoeUbkNbF8X7wQ0BQBM3XYSe8/elDgRERFVJ+UqSs2dOxdLlixB9+7dMWTIEHh5eQEAtm/fbnysj6gmaeFmg9BRfrBQyvHfhWS8tT4a+XqD1LGIiKiaiIqKMraX7vfGG28gKipKgkREFefNZxrjpfZ1YRCBN9YdwcnraVJHIiKiaqJcRanu3bsjOTkZycnJWLFihXH9uHHjsHjx4goLR2RK2tWzw9LADlDKZdh5KgEf/nyCg3oSEVGZqFQqXLp0CVOmTMGQIUNw82ZBb5I//vgD+fl8LJyqN0EQMLt/G3Ru7ICsXD1GhUZw5mIiIiqTchWlsrOzodPpYGdnBwC4evUq5s+fj3PnzsHZ2blCAxKZks6NHfG/oT6QywT8fOQaPt1xGqLIwhQREZXun3/+QZs2bRAWFoYtW7YgIyMDAHDs2DFMnz5d4nREj0+pkGHR8PZo5mKNm+k6jAqJgDaHE8QQEVHpylWU6tu3L1atWgUASE1Nhb+/P77++mv069cPixYtqtCARKamRytXfPVSwaCeoQev4Nu/LkiciIiITN1HH32EWbNmYffu3VAqlcb1Tz/9NA4fPixhMqKKY6M2w4pgXzhbq3AuMR2vrzmCPA53QEREpShXUerIkSN48sknAQA//fQTXFxccPXqVaxatQrff/99mY/z77//ok+fPnB3d4cgCNi2bVuh97ds2YLnnnsODg4OEAQB0dHR5YlLVOEGtKuLT/u2AgB8v+cClv13WeJERERkyk6cOIH+/fsXWe/s7Izk5GQJEhFVjjq25lgR5AsLpRz7LyZj8pYT7FVOREQlKldRKisrC9bW1gCAP//8EwMGDIBMJsMTTzyBq1fLPhVsZmYmvLy8sHDhwhLf79KlC+bOnVuemESVKrCjJ97v0QwAMOu3M9gQHitxIiIiMlW2tra4ceNGkfVHjx5FnTp1JEhEVHla19Fg4dB2kAnAT1HX8L+/L0odiYiITJSiPDs1btwY27ZtQ//+/bFr1y688847AICbN2/CxsamzMfp1asXevXqVeL7I0aMAABcuXKlPDGJKt3r3RtBm52HJf9exuStJ2ClVuCFtu5SxyIiIhPzyiuv4MMPP8TmzZshCAIMBgMOHDiA9957D4GBgVLHI6pwTzV3xqd9W2PKtpP4Zvd51LUzx4B2daWORUREJqZcPaWmTZuG9957D56envDz80PHjh0BFPSa8vHxqdCAj0qn00Gr1RZaiCqLIAj4qFdzDPGrB1EE3tkYjb3nbkodi4iITMzs2bPRvHlzeHh4ICMjAy1btkTXrl3RqVMnTJkyRep4RJVi+BP1Mb5bQwDAhz8fx8GLfFSViIgKK1dR6qWXXkJsbCwiIyOxa9cu4/pnnnkG3377bYWFK485c+ZAo9EYFw8PD0nzUM0nCAJm9WuNPl7uyNOLeHV1FMIu35I6FhERmRClUomlS5fi0qVL2LFjB9asWYOzZ89i9erVkMvlUscjqjQf9miO3m3dkKcXMX5NFC4kpksdiYiITEi5ilIA4OrqCh8fH8THx+PatWsAAD8/PzRv3rzCwpXH5MmTkZaWZlzi4uIkzUO1g1wm4JtBXni6uTN0+QaMXhmJE9fSpI5FREQmpl69enj++ecxaNAgNGnSROo4RJVOJhPw9cte6FDfDuk5+QgKicDN9BypYxERkYko15hSBoMBs2bNwtdff42MjAwAgLW1Nd5991188sknkMnKXet6bCqVCiqVSrLzU+1lJpfhh2HtMHJFOMJiUjAyJBybxj+Bxs7WUkcjIiIJTJo0qczbfvPNN5WYhEhaajM5lgZ2wIBFBxGTnInRoZHYMO4JWKrK9U8RIiKqQcr1m+CTTz7B8uXL8cUXX6Bz584AgP3792PGjBnIycnB559/XqEhiaoLtZkcy0Z2wLBlYTh+LQ3DloXhp1c7wcPeQupoRERUxY4ePVqm7QRBqOQkRNKzs1QiJMgXAxYdxInraXhz/VH8GNgBchn//BMR1WblKkqtXLkSy5Ytw4svvmhc17ZtW9SpUwevv/56mYtSGRkZuHjx3hSxMTExiI6Ohr29PerVq4eUlBTExsYiPj4eAHDu3DkABY8Ourq6lic6UaWzVpshNNgPg5ccwoWbGRi+PAybx3eEs41a6mhERFSF9u7dK3UEIpPi6WiJpYEdMHTpYew5exMzfz2FmS+2YmGWiKgWK9dzdikpKcWOHdW8eXOkpKSU+TiRkZHw8fExztg3adIk+Pj4YNq0aQCA7du3w8fHB7179wZQMJ2yj48PFi9eXJ7YRFXG3lKJNWP84WFvjqu3sjBieThSs3KljkVERCYgLi6OY15SrdW+vh3mD/aGIACrDl3Fsv9ipI5EREQSKldRysvLCwsWLCiyfsGCBWjbtm2Zj9O9e3eIolhkCQ0NBQAEBQUV+/6MGTPKE5uoSrnYqLF29BNwtlbhXGI6RoZEIEOXL3UsIiKSQH5+PqZOnQqNRgNPT094enpCo9FgypQpyMvLkzoeUZXq1cYNnzzfAgDw+e9n8PuJGxInIiIiqZTr8b0vv/wSvXv3xl9//YWOHTsCAA4dOoS4uDj8/vvvFRqQqDqr52CBNWP8MWjJIRyLS8XYlZEICfaF2ozTfxMR1SYTJ07Eli1b8OWXXxZqO82YMQO3bt3CokWLJE5IVLVGd2mA2JQsrDp0Fe9sjIaLjRrt69tJHYuIiKpYuXpKdevWDefPn0f//v2RmpqK1NRUDBgwAKdOncLq1asrOiNRtdbUxRorg/1gpVLg0OVbmLDuKPL0BqljERFRFVq3bh1CQ0Mxfvx4tG3bFm3btsX48eOxfPlyrFu3Tup4RFVOEARM79MKAS2cocs3YOyqSFxJzpQ6FhERVTFBFEWxog527NgxtGvXDnq9vqIO+di0Wi00Gg3S0tJgY2MjdRyqxQ5fvoWRK8Khyzegn7c7vhnkDRlnnCEiMkkV3X5wdnbGP//8gxYtWhRaf+bMGXTt2hVJSUmPfY7KwrYUVaas3HwMXnIYJ66nwdPBAlte7wx7S6XUsYiI6DGVtf1Qrp5SRPTonmjogEXD20EhE7AtOh7Ttp9EBdaEiYjIhE2YMAGfffYZdDqdcZ1Op8Pnn3+OCRMmSJiMSFoWSgWWB3VAHVtzXLmVhXGrIpGTZzofcBMRUeViUYqoCj3d3AVfD/KCIABrDsfiq13npI5ERERV4OjRo9ixYwfq1q2LgIAABAQEoG7duvj1119x7NgxDBgwwLgQ1TbO1mqEBvvCWq1A5NXbeHfTMRgM/OCOiKg2KNdA50RUfn296yBTp8fHW0/gh32XYK02w2vdG0kdi4iIKpGtrS0GDhxYaJ2Hh4dEaYhMTxMXaywZ0R4jV4TjtxM3UNfeHJN7tXj4jkREVK09UlHqYZ/epaamPk4WolpjqH89pOfkYc4fZzF351lYqxUY/kR9qWMREVElEEURM2fOhJOTE8zNzaWOQ2SyOjVyxNyBbTFp0zEs+ecyPOws2D4iIqrhHqkopdFoHvp+YGDgYwUiqi3Gd2sEbU4eFu69hKm/nIS1WoG+3nWkjkVERBVMFEU0btwYp06dQpMmTaSOQ2TSBrSri2u3s/HN7vOY9stJ1LE1x1PNnaWORUREleSRilIhISGVlYOoVnrvuWZIz8nHqkNXMWnTMVgqFQho6SJ1LCIiqkAymQxNmjTBrVu3WJQiKoOJTzdGXEoWNkddwxvrjmDT+I5oXaf0D8eJiKh64kDnRBISBAEz+rRCf5860BtEvL7uCA5eSpY6FhERVbAvvvgC77//Pk6ePCl1FCKTJwgCZg9ogy6NHZGVq0dwaASup2ZLHYuIiCoBi1JEEpPJBHz1Uls829IFufkGjF0Ziei4VKljERFRBQoMDER4eDi8vLxgbm4Oe3v7QgsRFWYml+GH4e3QzMUaSek6BIeEQ5uTJ3UsIiKqYJx9j8gEKOQy/G+ID0avjMCBi7cQFBKOjeM6opmrtdTRiIioAsyfP7/CjrVw4UJ89dVXSEhIgJeXF/73v//Bz8/voftt2LABQ4YMQd++fbFt27YKy0NUWWzUZggJ9kW/hQdwPjEDr62JQkiQH5QKfq5ORFRTCKIoilKHqExarRYajQZpaWmwsbGROg5RqTJ1+Ri2LAzRcalwslbhp1c7or6DpdSxiIhqHVNtP2zcuBGBgYFYvHgx/P39MX/+fGzevBnnzp2Ds3PJg0FfuXIFXbp0QcOGDWFvb/9IRSlTvRdUe5y8nobBSw4hM1ePge3qYt7LbSEIgtSxiIioFGVtP/BjBiITYqlSIDTYF81dC7qqD1sWhoS0HKljERFRBbh06RKmTJmCIUOG4ObNmwCAP/74A6dOnSrzMb755huMHTsWwcHBaNmyJRYvXgwLCwusWLGixH30ej2GDRuGmTNnomHDho99HURVrXUdDRYMawe5TMDPR67h+z0XpY5EREQVhEUpIhNja6HEqtF+qO9ggWu3szF8eRhSMnOljkVERI/hn3/+QZs2bRAWFoYtW7YgIyMDAHDs2DFMnz69TMfIzc1FVFQUAgICjOtkMhkCAgJw6NChEvf79NNP4ezsjNGjR5fpPDqdDlqtttBCJLWnmjnj076tAADf/nUeP0ddkzgRERFVBBaliEyQs7Uaa0b7w02jxsWbGRi5goN7EhFVZx999BFmzZqF3bt3Q6lUGtc//fTTOHz4cJmOkZycDL1eDxcXl0LrXVxckJCQUOw++/fvx/Lly7F06dIyZ50zZw40Go1x8fDwKPO+RJVpmH99vNqtEQDgw5+P4+BFzlhMRFTdsShFZKI87C2werQ/7C2VOHE9DWNCI5Gdq5c6FhERlcOJEyfQv3//IuudnZ2RnFw5/7BOT0/HiBEjsHTpUjg6OpZ5v8mTJyMtLc24xMXFVUo+ovL4oEczvNDWDfkGEePXROF8YrrUkYiI6DGwKEVkwho7W2HVKD9YqxQIv5KC19ZGITffIHUsIiJ6RLa2trhx40aR9UePHkWdOnXKdAxHR0fI5XIkJiYWWp+YmAhXV9ci21+6dAlXrlxBnz59oFAooFAosGrVKmzfvh0KhQKXLl0q9jwqlQo2NjaFFiJTIZMJmPeyF3w97ZCek4/gkAjc1HL8TSKi6opFKSIT17qOBiuCfaE2k2HfuSS8sykaekONnjSTiKjGeeWVV/Dhhx8iISEBgiDAYDDgwIEDeO+99xAYGFimYyiVSrRv3x579uwxrjMYDNizZw86duxYZPvmzZvjxIkTiI6ONi4vvvginnrqKURHR/OxPKq21GZy/DiiAxo6WuJ6ajZGrYxApi5f6lhERFQOLEoRVQO+nvZYPLw9zOQCfjt+A59sPQFRZGGKiKi6mD17Nlq0aIF69eohIyMDLVu2RNeuXdGpUydMmTKlzMeZNGkSli5dipUrV+LMmTN47bXXkJmZieDgYABAYGAgJk+eDABQq9Vo3bp1ocXW1hbW1tZo3bp1obGtiKobO0slQoJ9YW+pxMnrWkxcfxT5evYmJyKqbhRSByCisunezBnzB/tg4voj2BARB2u1Ah8/3wKCIEgdjYiISmAwGPDVV19h+/btyM3NxYgRIzBw4EBkZGTAx8cHTZo0eaTjDR48GElJSZg2bRoSEhLg7e2NnTt3Ggc/j42NhUzGzxypdqjvYIllIztgyI+H8ffZm5j562l82rcV20ZERNWIINbw7hZarRYajQZpaWkcE4FqhE0Rcfjg5+MAgPeea4oJTz/aP2iIiOjhKqr98Nlnn2HGjBkICAiAubk5du3ahSFDhmDFihUVmLZysS1Fpm7nyRt4be0RiCLw8fPNMa5rI6kjERHVemVtP/CjNKJqZpCvB6a+0BIAMO/P8wg9ECNxIiIiKsmqVavwww8/YNeuXdi2bRt+/fVXrF27FgYDHzMiqig9W7vhk+dbAABm/34Wvx0vOqkAERGZJhaliKqh0V0a4K1nCnpIzfj1NH6OuiZxIiIiKk5sbCyef/554+uAgAAIgoD4+HgJUxHVPKO7NMDIjvUBAO9sikbU1RSJExERUVmwKEVUTb0d0ATBnT0BAO//dAw7TyZIG4iIiIrIz8+HWq0utM7MzAx5eXkSJSKqmQRBwLQ+rRDQwgW5+QaMWRmJmORMqWMREdFDcKBzompKEARM7d0S6Tn5+CnqGt5cfxTLgzrgySZOUkcjIqI7RFFEUFAQVCqVcV1OTg5effVVWFpaGtdt2bJFinhENYpcJuD7Id545cfDOH4tDcEh4djyemfYW3KmSSIiU8WeUkTVmEwm4IsBbdCrtSty9QaMWxWFqKu3pY5FRER3jBw5Es7OztBoNMZl+PDhcHd3L7SOiCqGhVKBZSM7oI6tOa7cysLYVZHIydNLHYuIiErA2feIagBdvh5jVkbivwvJsFErsGFcR7R05593IqLyYvvhHt4Lqo4u3kzHgB8OQpuTj95t3PC/IT6QyQSpYxER1RqcfY+oFlEp5Fgyoj061LeDNicfgSvCcDkpQ+pYRERERJJo7GyNJSM6wEwu4LcTNzB351mpIxERUTFYlCKqISyUCiwP8kVLNxskZ+Ri+LIwXE/NljoWERERkSQ6NnLAly+1BQAs+fcyVh++KnEiIiJ6EItSRDWIxtwMq0b7oaGjJeLTcjBiWRiSM3RSxyIiIiKSRH+funj32aYAgOm/nMSeM4kSJyIiovuxKEVUwzhaqbBmjD/q2JrjcnImApeHIy2bU48TERFR7TTh6cYY1KEuDCIwYd1RnLiWJnUkIiK6g0UpohrI3dYca8b4w9FKhdM3tBgVGoGs3HypYxERERFVOUEQ8Hn/NniyiSOy8/QYtTIC125nSR2LiIjAohRRjdXA0RKrR/vBRq1A1NXbGL86Crp8TolMREREtY+ZXIaFw9qhuas1ktJ1GBUawZ7kREQmgEUpohqshZsNQoL9YKGU478LyXh7QzTy9QapYxERERFVORu1GVYE+cLFRoXziRl4bU0UcvPZLiIikhKLUkQ1XPv6dvhxRAco5TL8cTIBH205AYNBlDoWERERUZVztzXHiiBfWCrlOHjpFj7achyiyHYREZFUWJQiqgW6NHHE90N8IJcJ+CnqGj7dcZoNMCIiIqqVWrlrsGBYO8hlArYcuY7v9lyQOhIRUa3FohRRLdGztSu+HNgWABB68Arm/8UGGBEREdVOTzVzxmd9WwMA5v91AT9FXZM4ERFR7cSiFFEtMrB9Xcx8sRUA4Ls9F7Dsv8sSJyIiIiKSxlD/eniteyMAwEc/H8eBi8kSJyIiqn0kLUr9+++/6NOnD9zd3SEIArZt21bofVEUMW3aNLi5ucHc3BwBAQG4cIG9O4gex8hOnnjvuaYAgFm/ncHGiFiJExERERFJ4/3nmqGPlzvyDSJeXR2FcwnpUkciIqpVJC1KZWZmwsvLCwsXLiz2/S+//BLff/89Fi9ejLCwMFhaWqJHjx7Iycmp4qRENcsbTzXGuK4NAQCTt5zAb8dvSJyIiIiIqOrJZAK+eqktfD3tkK7Lx6jQCNzU8t8aRERVRdKiVK9evTBr1iz079+/yHuiKGL+/PmYMmUK+vbti7Zt22LVqlWIj48v0qOKiB6NIAiY3Ks5hvh5wCACb288in3nbkodi4iIiKjKqc3k+HFEBzR0tMT11GyMWhmBTF2+1LGIiGoFkx1TKiYmBgkJCQgICDCu02g08Pf3x6FDhyRMRlQzCIKAWf3a4IW2bsjTi3h1TRTCY1KkjkVERERU5ewslQgN9oODpRInr2sxcf1R5OsNUsciIqrxTLYolZCQAABwcXEptN7FxcX4XnF0Oh20Wm2hhYiKJ5cJ+GaQN55q5oScPANGh0bg5PU0qWMRERERVbl6DhZYOrIDVAoZ/j57EzN+PQVRFKWORURUo5lsUaq85syZA41GY1w8PDykjkRk0pQKGX4Y1h5+DeyRrstH4IpwXLyZIXUsIiIioirXrp4dvnvFB4IArDkcix//5UzFRESVyWSLUq6urgCAxMTEQusTExON7xVn8uTJSEtLMy5xcXGVmpOoJjBXyrF8ZAe0qaNBSmYuhi8LQ1xKltSxiIiIiKpcz9aumNK7JQBgzh9nOSEMEVElMtmiVIMGDeDq6oo9e/YY12m1WoSFhaFjx44l7qdSqWBjY1NoIaKHs1abYeUoPzR2tkKCNgfDl4dx9hkiIiKqlUZ19kRQJ08AwDubohF5heNuEhFVBkmLUhkZGYiOjkZ0dDSAgsHNo6OjERsbC0EQ8Pbbb2PWrFnYvn07Tpw4gcDAQLi7u6Nfv35SxiaqsewtlVgz2h917cxx9VYWRiwPR2pWrtSxiIiIiKqUIAiY+kJLPNvSBbn5BoxdFYmY5EypYxER1TiSFqUiIyPh4+MDHx8fAMCkSZPg4+ODadOmAQA++OADTJw4EePGjYOvry8yMjKwc+dOqNVqKWMT1WiuGjXWjvGHs7UK5xLTERQSgQxOi0xERES1jFwm4LtXvOFVV4PbWXkICgnHrQyd1LGIiGoUQazhU0potVpoNBqkpaXxUT6iR3AuIR2DfzyE1Kw8dGrkgBVBvlCbyaWORURUJdh+uIf3gmq7pHQd+v9wANduZ6NdPVusG/sE20RERA9R1vaDyY4pRUTSauZqjdBgP1gq5Th46RYmrj+KPL1B6lhEREREVcrJWoXQYF/YqBU4EpuKdzZGw2Co0Z/rExFVGRaliKhE3h62WDbSF0qFDLtPJ+KDn46zEUZERES1TmNna/wY2AFmcgF/nEzAFzvPSh2JiKhGYFGKiErVsZEDFg1rB4VMwNaj1zF9+ynU8Kd+iYiIiIp4oqEDvnrJCwDw47+XsfrQFWkDERHVACxKEdFDPdPCBV8P8oIgAKsPX8W8P89JHYmIiIioyvXzqYP3nmsKAJi+/RT+Op0ocSIiouqNRSkiKpO+3nUwq19rAMDCvZew+J9LEiciIiIiqnpvPNUYgzt4wCACE9cfxYlraVJHIiKqtliUIqIyG+ZfHx/1ag4A+OKPs1gbdlXiRERERERVSxAEzOrfGk82cUR2nh6jVkbg2u0sqWMREVVLLEoR0SN5tVsjvN69EQBgyraT+CX6usSJiIiIiKqWmVyGH4a1Q3NXaySl6xAcEoG07DypYxERVTssShHRI3u/RzMMf6IeRBF4d9Mx7DnD8RSIiIiodrFWmyEk2BcuNipcuJmBV1dHITffIHUsIqJqhUUpInpkgiDg0xdbo5+3O/INIl5fewSHLt2SOhYRERFRlXLTmGNFkC8slXIcunwLH/18nLMUExE9AhaliKhcZDIBX73shYAWLtDlGzBmZQSOxaVKHYuIiIioSrVy12DhsHaQywRsOXod8/+6IHUkIqJqg0UpIio3M7kMC4b6oGNDB2Tm6jEyJBznE9OljkVERERUpbo3czbOUvzdngvYHBkncSIiouqBRSkieixqMzmWjuwAbw9bpGblYfiyMMTe4gw0REREVLsM8atnnAxm8pYT2H8hWeJERESmj0UpInpsVioFQoN90czFGjfTdRi2/DAS0nKkjkVERERUpd57rhle9CoYc/O1NVE4l8Ae5EREpWFRiogqhK2FEqtH+6G+gwXiUrIxYnkYUjJzpY5FREREVGUKxtxsCz9Pe6Tr8hEcEo5ELT+oIyIqCYtSRFRhnG3UWDPaH642aly4mYGRK8KRnpMndSwiIiKiKqNSyPFjYHs0dLJEfFoORoVGIFOXL3UsIiKTxKIUEVUoD3sLrBnjB3tLJU5cT8PolZHIydNLHYuIiIioythaKBEa5AcHSyVOxWsxYd0R5OsNUsciIjI5LEoRUYVr7GyNVaP8YK1SIDwmBa+tiUJuPhtiREREVHvUc7DAspEdoDaTYe+5JEzffgqiKEodi4jIpLAoRUSVonUdDZYH+UKlKGiITdoUDb2BDTEiIiKqPXzq2eG7V3wgCMDasFgs+fey1JGIiEwKi1JEVGn8Gthj8Yj2MJML2HH8BqZsO8FPCImIiKhW6dHKFVN7twQAfPHHWew4Hi9xIiIi08GiFBFVqqeaOWP+YB/IBGB9eBzm/HGWhSkiosewcOFCeHp6Qq1Ww9/fH+Hh4SVuu3TpUjz55JOws7ODnZ0dAgICSt2eiCrHqC4NENTJEwAwadMxRF5JkTYQEZGJYFGKiCpd77ZumDOgDQDgx38v44d9lyRORERUPW3cuBGTJk3C9OnTceTIEXh5eaFHjx64efNmsdvv27cPQ4YMwd69e3Ho0CF4eHjgueeew/Xr16s4ORFNfaElnm3pgtx8A8asisTlpAypIxERSU4Qa3iXBa1WC41Gg7S0NNjY2Egdh6hWW/bfZcz67QwAYOaLrTDyzieGRESmxlTbD/7+/vD19cWCBQsAAAaDAR4eHpg4cSI++uijh+6v1+thZ2eHBQsWIDAwsEznNNV7QVQdZefq8cqPh3DsWhrqO1hgy2ud4GClkjoWEVGFK2v7gT2liKjKjHmyId58pgkAYPr2U/g56prEiYiIqo/c3FxERUUhICDAuE4mkyEgIACHDh0q0zGysrKQl5cHe3v7ErfR6XTQarWFFiKqGOZKOZaN9IWHvTmu3srCmFWRyMnTSx2LiEgyLEoRUZV6J6CJcUyFD34+jl2nEqQNRERUTSQnJ0Ov18PFxaXQehcXFyQklO3/pR9++CHc3d0LFbYeNGfOHGg0GuPi4eHxWLmJqDAnaxVCgvxgo1bgaGwq3tkYDQNnKCaiWopFKSKqUoIgYNoLLfFS+7rQG0RMXHcU+y8kSx2LiKjG++KLL7BhwwZs3boVarW6xO0mT56MtLQ04xIXF1eFKYlqh8bOVvgxsAOUchn+OJmAOX+ckToSEZEkWJQioionkwn4YkAb9Gzlily9AeNWRyLq6m2pYxERmTRHR0fI5XIkJiYWWp+YmAhXV9dS9503bx6++OIL/Pnnn2jbtm2p26pUKtjY2BRaiKjiPdHQAV+9XPD3cel/MVh16Iq0gYiIJMCiFBFJQiGX4bsh3niyiSOycvUIDgnHmRsct4SIqCRKpRLt27fHnj17jOsMBgP27NmDjh07lrjfl19+ic8++ww7d+5Ehw4dqiIqEZVRX+86eL9HMwDAjO2n8NfpxIfsQURUs7AoRUSSUSnkWDKiPdrXt4M2Jx8jlocjJjlT6lhERCZr0qRJWLp0KVauXIkzZ87gtddeQ2ZmJoKDgwEAgYGBmDx5snH7uXPnYurUqVixYgU8PT2RkJCAhIQEZGRwKnoiU/F690Z4xdcDBhGYuP4ojl9LlToSEVGVYVGKiCRloVRgRZAvWrrZIDlDh+HLwhCfmi11LCIikzR48GDMmzcP06ZNg7e3N6Kjo7Fz507j4OexsbG4ceOGcftFixYhNzcXL730Etzc3IzLvHnzpLoEInqAIAj4rF9rdG3qhOw8PUaFRiIuJUvqWEREVUIQRbFGT/Wg1Wqh0WiQlpbGMRGITFhyhg6DFh/C5eRMNHSyxKbxHeFopZI6FhHVUmw/3MN7QVQ10nPy8PLiQzibkI7Gzlb4+dVO0FiYSR2LiKhcytp+YE8pIjIJjlYqrB7jD3eNGpeTMhG4PBxp2XlSxyIiIiKqEtZqM4QE+8LVRo2LNzMwfk0kcvMNUsciIqpULEoRkcmoY2uONWP84WilxOkbWowOjUBWbr7UsYiIiIiqhJvGHCuCfGGlUuDw5RR89PNx1PAHW4iolmNRiohMSkMnK6wa5Q9rtQKRV29j/Ooo6PL1UsciIiIiqhIt3W2wcFg7yGUCthy9jm93n5c6EhFRpWFRiohMTkt3G4QG+8LcTI7/LiTj7Q3RyNez+zoRERHVDt2aOuHzfq0BAN//fRGbIuMkTkREVDlYlCIik9S+vj1+DGwPpVyGP04mYPKWEzAY2H2diIiIaodX/OrhjacaAQA+3nIC+y8kS5yIiKjisShFRCbrySZO+H6ID2QCsDnqGj777TTHVSAiIqJa473nmqGvtzvyDSJeWxOFswlaqSMREVUoFqWIyKT1bO2KL1/yAgCEHLiC7/ZckDgRERERUdUQBAFfvtQWfg3ska7Lx6iQCCRqc6SORURUYViUIiKT91L7upjRpyUAYP5fF7B8f4zEiYiIiIiqhkohx48j2qOhkyXi03IQHBKBDB1nJyaimoFFKSKqFoI6N8C7zzYFAHy24zQ2RXDATyIiIqodbC2UWBnsB0crJU7f0GLCuiOcBIaIagQWpYio2pjwdGOMfbIBAOCjLcfx+4kbEiciIiIiqhoe9hZYNtIXajMZ9p1LwrTtpzjWJhFVeyZflEpPT8fbb7+N+vXrw9zcHJ06dUJERITUsYhIAoIg4OPnW2BwBw8YROCtDUfxz/kkqWMRERERVQlvD1t894oPBAFYFxaLxf9cljoSEdFjMfmi1JgxY7B7926sXr0aJ06cwHPPPYeAgABcv35d6mhEJAFBEDB7QBv0buuGPL2I8asjEXElRepYRERERFWiRytXTO1dMNbm3J1n8euxeIkTERGVn0kXpbKzs/Hzzz/jyy+/RNeuXdG4cWPMmDEDjRs3xqJFi6SOR0QSkcsEfDvIG92bOSEnz4BRIRE4eT1N6lhEREREVWJUlwYI7uwJAHh30zF+QEdE1ZZJF6Xy8/Oh1+uhVqsLrTc3N8f+/fuL3Uen00Gr1RZaiKjmUSpkWDSsPfw8C6ZIDlwRjos3M6SORURERFQlpvRuiedauiBXb8DYVZG4lMR2EBFVPyZdlLK2tkbHjh3x2WefIT4+Hnq9HmvWrMGhQ4dw40bxAxzPmTMHGo3GuHh4eFRuyBvHgYwkgIMMElU5c6Ucy4I6oHUdG6Rk5mLE8jBcu50ldSwiIiKiSieXCfjuFR94edgiNSsPwSERuJWhkzoWEdEjEUQTn7Lh0qVLGDVqFP7991/I5XK0a9cOTZs2RVRUFM6cOVNke51OB53u3v+MtVotPDw8kJaWBhsbm4oNJ4rA7DpAXiagtAbsGwD2De8tDo0Kvlq5AIJQsecmIqOUzFwMWnIIF29mwNPBApte7Qhna/XDdyQiKoFWq4VGo6mc9kM1w3tBZNqSM3To/8MBxKVkw6eeLdaPfQJqM7nUsYiolitr+8Hki1J3ZWZmQqvVws3NDYMHD0ZGRgZ+++23h+5XqQ2p7NvA4q5AWhyAUm6jmcWdQtUDRSv7hoC1OyAz6Q5rRNVCQloOXlp8ENduZ6O5qzU2jusIjYWZ1LGIqJpiIeYe3gsi03fxZgYGLjqItOw89GzlioXD2kEu44fiRCSdGleUuuv27dto0KABvvzyS4wbN+6h21dJQyovB0i9CqRcLrqkxgKioeR9FWrArkHxRStNXUDGTzmIyupKciZeXnIISek6+NSzxZrR/rBUKaSORUTVEAsx9/BeEFUPYZdvYcTycOTqDRjTpQGmvNBS6khEVIvVmKLUrl27IIoimjVrhosXL+L999+HWq3Gf//9BzOzh/eCkLwhlZ9b0JMq5TJw69IDBaurgCG/5H1lZoCd5wOPA94pXGnqAXL+Y5voQecS0jFoySGkZeehc2MHLB/pyy7sRPTIJG8/mBDeC6Lq45fo63hrQzQAYOaLrTCyk6ekeYio9ipr+8HkqxppaWmYPHkyrl27Bnt7ewwcOBCff/55mQpSJkGhLCgmOTQCmjxb+D19/r2CVcplICXmztdLwO0rgD4XuHWhYHmQTAHY1iv6OKB9Q8C2fsF5iWqhZq7WWDnKD8OWHsaBi7cwcf1RLBrWDgo5H5MlIiKimq2vdx1cu52Nr3adw8xfT8Hd1hzPtnSROhYRUYlMvqfU46q2n+4Z9ID2+gOPA8bc+z4/p+R9BRmg8Si+YGXnCZhxAGiq+Q5eSkZQSARy8w0Y4FMH8172goxjKxBRGVXb9kMl4L0gql5EUcTkLSewISIOajMZNo7rCC8PW6ljEVEtU2Me33tcNbIhZTAAGQnFPBJ4p2iVl1nKzgJgU+feY4B3Zwi0b1gwtpXSosoug6iy7T6diFfXREFvEBHYsT5mvtgKAmfCJKIyqJHth3LivSCqfvL0BoxeGYl/zyfB0UqFra93goc92/lEVHVYlLqj1jWkRBHIuFnMoOuXCopWOm3p+1u7lTxToMq6aq6BqAL9En0db2+MhigCE55qjPd6NJM6EhFVA7Wu/VAK3gui6ilDl4+XFx/CmRtaNHa2ws+vduLMxERUZViUuoMNqfuIIpB1q/hZAlMuA9m3S9/f0vmBQtV9hStz2yq5BKLyWH34KqZuOwkAmNyrOcZ3ayRxIiIydWw/3MN7QVR93UjLRv+FB5GgzcETDe2xcpQfVApOAENElY9FqTvYkHoEWSnA7RjgVjEFq6zk0vc1t39glsD7ilfmdgAfmSKJ/bDvIr7ceQ4AMLt/Gwz1rydxIiIyZWw/3MN7QVS9nbmhxcuLDyFDl4/+PnXwzSAvDmdARJWuxsy+R1XIwr5gqdO+6Hs5aYUHWk+JufNI4GUgIxHITgGupwDXI4vuq9YUP+i6fUPA0okFK6oSr3dvjPScfCzadwmfbDsBK7UCL3q5Sx2LiIiIqFK1cLPBD8PaITg0AluPXkddO3O8+xyHMyAi08CiFJWNWgO4excsD9JlFPSwKm6mQO31goJW/NGC5UFK6+LHr7JvCFi7smBFFeqDHs2gzc7D2rBYTNoYDSuVHE835zTJREREVLN1beqE2f1b48OfT+B/f1+Eh50FBvl6SB2LiIhFKaoAKivAtU3B8qC87Ad6WN1XtEqLA3LTgYTjBcuDzCwKZgS0b1D0kUBrd0Amq/xroxpFEAR81rc1MnT5+CU6Hq+tOYKVo/zwREMHqaMRERERVarBvvUQl5KNBXsv4uOtJ+Bmq8aTTZykjkVEtRzHlCLp5OuA21eLmSXwMpAaC4iGkveVqx7oYXXf9xoPQMYBHKlkeXoDXlsThb/O3AQA2FqYwdFKBQdLZcFXq3tfHSxVcLzvtZVKwXEYiGoBth/u4b0gqjlEUcTbG6PxS3Q8rFQKbH61I1q48e81EVU8DnR+BxtS1VR+bkFPquJmCbx9BTDkl7yvzAyw8yzmkcAGgG09QM6pcAnIydPjjbVHsOfszUfaT6mQwdFSCUfrgiKWg5UKjlYFhat7RayC13aWSpjJ2aOPqDpi++Ee3guimkWXr0fg8nCExaTATaPG1tc7w1WjljoWEdUwLErdwYZUDaTPf6Bgdd/jgbdjAH1uyfsK8oLCVHGzBNrWBxTKqrsOMgm3MnRIzsgt+Jp552uGDrcycgvWZ957nZWrf+Tjl6UXlsOdIhZ7YRGZDrYf7uG9IKp50rLyMGDRAVxKykQLNxtsfrUjrFQc2YWIKg6LUnewIVXLGPSANr74HlYpMUB+dsn7CjJAU7f4QdftGgBm/ASptsvKzb9TrCooUhUUrAq/vvt+SmYuDI/4f9e7vbAcrO4VqxyslHC0VMHRuqCI5WClhJOVir2wiCoZ2w/38F4Q1UxxKVno/8MBJGfkoltTJywb2YFtCyKqMCxK3cGGFBkZDEBGQvEFq1uXgbzMUnYWAJs6JcwU2ABQWlbZZVD1oDeISM3Kxa3MXCSn3+uFdbdolfxAEau8vbDu9sAq1PvKmr2wiB4X2w/38F4Q1VzH4lIx+MdDyMkzYIifB2b3b8P2AhFVCBal7mBDispEFIGMmyX0sLoM6LSl72/leueRwGJ6WKn5544e7m4vrLtFrLu9sIw9szLvPVKYkqmrtF5YjlYq2LMXFhHbD/fhvSCq2f48lYDxa6IgisAHPZvh9e6NpY5ERDUAi1J3sCFFj00UgayUojME3l2yb5e+v6VT8Y8E2jcEzG2r5BKoZinUC+u+MbHuPkKYlH6vF9atDB0yH6MXloOVCk739cK6W7i6v7BlzV5YVAOx/XAP7wVRzRdyIAYzfz0NAPh+iA9e9HKXOBERVXdlbT9wNDuihxEEwNKhYPHwLfp+VkrBAOv3D7h+d8lMurfEhRXd19y+5IKVhX3BuYkeIJcJdwpCKjR1sX7o9vf3wro7kPvdXlj3D+R+fy+s1Kw8pGbl4VJSaY+1Fri/F9b9A7k7Wj7wmr2wiIiITFJw5waIS8nGigMxeG/TMbjaqOHXwF7qWERUC7CnFFFlykl7oFh13/cZCaXvq9IUjFf14CyB9g0Lel+xYEWV4MFeWKUO7F4BvbAc7xatjAWsu0Us9sIiabH9cA/vBVHtoDeIeH1tFHadSoTG3AxbXu+ERk5WUsciomqKj+/dwYYUmSxdBnD7ygOPBN4pWmmvl76v0qqYQdfvFK+sXVmwoiqTnau/M+bVvUcIk4qZjbAixsK6fyD3u72w7i9ssRcWVSS2H+7hvSCqPbJz9Riy9DCi41JRz94CW17vBEcrldSxiKgaYlHqDjakqFrKy76vYPXALIFpcQBK+WurML83K+CDPaxs6gAy/qOdpGEwiEjNzrtTpKqcXlgac7NCsw4WzEJ4rxeWw30zFbIXFpWG7Yd7eC+IapfkDB0G/HAQsSlZ8PawxfqxT8BcKZc6FhFVMyxK3cGGFNU4+Trg9tXiZwlMjQXEUv4hL1cBdp73PRJ4X+FK4wHI2OAg01FcL6zkTB2S0yuoF5ZcVmjMq4IC1n2vrVRwsFTCyZq9sGojth/u4b0gqn0uJWVgwA8HkZadhx6tXPDDsPaQy/hBDhGVHYtSd7AhRbWKPq+gMJUSU3SWwNtXAEN+yfvKzAC7+sU8EtgAsK0HyM2q7DKIHtXdXli3MnT3Hh+8U9C6f4bC5MfshVVo9sHiZiO0VMLRWsVeWDUA2w/38F4Q1U7hMSkYviwMuXoDRndpgKkvtJQ6EhFVIyxK3cGGFNEd+nxAe63ooOu3LhXMHqjPLXlfQV5QmCpulkC7+oCCYw1Q9ZKdqzc+MliZvbAc7hvI3fH+13cLWHfGwlIq2AvL1LD9cA/vBVHttf1YPN5cfxQAMKNPSwR1biBxIiKqLsraflBUYSYikpJcUfDonp0n0Ojpwu8Z9IA2vphHAu8UrvKzCwpXt2OAS3seOLBQ8OifQ3EFK0/AzLxqro/oEZgr5airtEBdO4uHblvWXli3MnORnF7QCytXb8CNtBzcSMspUx5jL6w7A7k73DeQu9N9vbAcrFSwUbMXFhERVY0Xvdxx7XYWvtx5DjN3nIa7rTmea+UqdSwiqkHYU4qISieKQHrCA7ME3le0ys0ofX+bOg+MX3XfeFZKy6q5BqIqdLcX1v0DuSc/+PpOESslMxf6R+yGdX8vrLsDuTve/9qavbAqAtsP9/BeENVuoiji460nsD48DmozGTaO6wgvD1upYxGRiePje3ewIUVUiUQRyEwqZpbASwUFK11a6ftbud7Xs+qB2QLV/PtKNd/9vbDuzT54txdW4de3MnKRoStlXLgS3N8Ly+GBgdwd74yBZdK9sEQREA0FY+YZ8u8s+nvfqzWAyqrCT8v2wz28F0SUrzdg9MpI/HM+CY5WSmx9vTM87B/e25iIai8Wpe5gQ4pIIqIIZKUUP0tgymUgO6X0/S0c75sl8IHClbld1VwDkSkxGJCt0yElPRMp6Vm4nZGF2+nZSM3MRlpGNtIys6HNzIE2Kxvp2TpkZudAMOghhx5mQsFXBQx3vuohh+HeV6Hgq0pmgEYlwEYJWCsFWCsBazMBlmYiLBUCLMxEWCgAc7kItVyEHHeKQ/r8+wpGDxSNSnxdQpGpuNel6fM90H5khd9uth/u4b0gIgDI0OXj5cWHcOaGFo2cLLHltc7QWHAiHCIqHseUIiJpCQJg6VCwePgWfT/7duFxq+5fMpOArOSCJS6s6L7mdsXMEnjnewv7gnNTzWQwAOLdQkjeIxRA7n7/iPuUeI7SjlFR53iwMCPCHECdO8tDlfffCfl3lqxy7l+VZGYFvaiIiKjSWakUCAnyRf8fDuBSUibGrY7EqtF+UCnkUkcjomqMPaWIyPTkaAsGVS/0SOCdrxkJpe+r0hR9FPDuYuVcMwpWolhCkaS0AsgD6/R5ZSiaPEahpczneLBg9JDtWYAoSqa4b5EX89rsIe8XfK8X5Mg1CNAZZMgxyJCjF5CdLyArH8i68zUjr2DJzAPyRBnyRRn0kCMfMuRDgXzcfS2HHjLki3e+Qg7I5LBQq2FproKluRpW5ipYW5jD2kINGwtz2FiqYWtpDlsrC2gszaFUmpWQ9e76yh0ry5TbDwsXLsRXX32FhIQEeHl54X//+x/8/PxK3H7z5s2YOnUqrly5giZNmmDu3Ll4/vnny3y+Sr0X2htA0hkAQsH/nwXZve9LW2d878F1shK2u/8YeMhxizuGrPC+j5WXqHo7c0OLlxcfQoYuH/283fHtYG/Te/SbiCTHnlJEVH2pbQA3r4LlQbmZxfeuSokBtNcKxrG6EV2wPEhpVbRgZeV6r+dNWXvEPPKjSo9aMHrI9qK+sn8C1Y/wQLFF/rBCjaKYdWYPeb+E13KzRzjH3e/Lss+D11TMPvf/Q/kxyQGY31kexmAQkZadd2/2wfsGck/OyMXt+2YnNI6FZQCQcWcpIr/ImzZqxZ1B3FWFB3a3LhgLy+HOejeNGhbK2tOc2bhxIyZNmoTFixfD398f8+fPR48ePXDu3Dk4OzsX2f7gwYMYMmQI5syZgxdeeAHr1q1Dv379cOTIEbRu3VqCK3jApb+BX16XOkUVe9QimgAIKEcR7cFzlbWIhocct6S8KGNx7sFj4BHuw/3rynIvSzpuGc9V5Bil3ZvS8uIhxzW1vKXf3xYyAStfsMInW0/hxLHreP3GGZgr5RAKdipc+zWuu9cPQhDurkWhrwWFLfHO9yi0xf2/6gQBkImFb2vBlsZv7h1XQAnnum/dffsXWv/gsR7IUeT4910vAMggGq/33g7FnUt84B4UzVXwn4j7T3///b6Xt+g9vD9TofVFYxXKZbwOQTRu8eA+91/7vfMWPt/9Oxa8f/d6i55LuD+vIN53fAEPbHrf/RZLuJZ7LwrOdd99fmDrB/98Ffkzc//PttDPTXjgHtz7ed3bVLx/tyI/L+N+4v3XUdz9FozHK+5cD157kT/LD6y7/1xubZ+BTC5dj0f2lCKimiMvG7h9pfgxrNKu1fxeNoKszL1iCr2Wl1SMKe11OYoqRYpFZS0YlWEffkJr0nLy9AVFqnQdbmXeKWSVMLD7o85IOPWFlhjdpUGFZzbV9oO/vz98fX2xYMECAIDBYICHhwcmTpyIjz76qMj2gwcPRmZmJnbs2GFc98QTT8Db2xuLFy8u0zkr9V6c/Q3YO7ugByjEewPb3/2+xHW489VQeLsS14klrCvmXA8eg4iIqAbL/SgBSnVZPpZ8NOwpRUS1j5k54NyiYHlQvg5IjS06S2BW8qMVciqrqFLcNvJHyCXIUdmPMxGVl9pMjjq25qhj+/AGz91eWLcydUhKv9cL61aGDkl3vhbMRlhQ3HK0UlbBFZiG3NxcREVFYfLkycZ1MpkMAQEBOHToULH7HDp0CJMmTSq0rkePHti2bVuJ59HpdNDpdMbXWq328YKXpnnvgsXUiaUVux5WRMNDCmalHRcPP1dFFOIqpOjHvJX756GM5ypyjNLuTUl5i9muhGPk6/W4+zmCWMpfoQIlf4BUeN+SthMfeFX2D6TKuu297Uq5GhEQi/swrJhdREEoy40pc/m77NfxeMcTH3xx93rv/Bku6fiPfp+LPeN9a4Si6/7f3r0HR1Wffxz/bALZhEwSQiO5aBpBMWLkUsVkgjpACSTIOKRjCzhIoyOlUnBgrG1tq4aM0wFblF6GwdLhYltNCirgVA1CJDhNQVoIGiwwQFPFYkBsIRfE2uzz+4NfthySkGxI9nJ4v2Z2yJ797tnvk2c3++Gbk7MdfZ+79ajdrPfC613s+FL1WidfX+qBL96fdXLPdo9rHX7Z7e9LZoh/ucuiFIArQz+vlDLs/AVA2IqK8ig5PkbJ8TG6vv1fo7Xj8gO+HU6dOqXW1lalpqY6tqempurgwYMd3qehoaHD8Q0NnZ+fb8mSJSorK7v8CbuJx3N+8R+AA/+ZBHC5+LU6AACIWJxct/f98Ic/1JkzZ/yXY8eOhXpKAADApVjcBgAAiAApKSmKjo7WiRMnHNtPnDihtLS0Du+TlpYW0HhJ8nq98nq9lz9hAACALnCkFAAAQASIiYnRrbfeqqqqKv82n8+nqqoq5efnd3if/Px8x3hJ2rp1a6fjAQAAgokjpQAAACLEI488opKSEo0ZM0a5ubn6+c9/rpaWFj3wwAOSpG9+85u6+uqrtWTJEknSwoULNW7cOD3zzDOaOnWqKioq9Ne//lWrVq0KZRkAAACSWJQCAACIGDNmzNAnn3yiJ598Ug0NDRo9erQqKyv9JzP/8MMPFXXBJ3GOHTtWL774oh5//HH96Ec/0rBhw7Rp0ybdfPPNoSoBAADAz2Mu/9iaxsZGJSUl6cyZM0pMTAz1dAAAQAQgP/wP3wsAABCo7uYHzikFAAAAAACAoGNRCgAAAAAAAEHHohQAAAAAAACCjkUpAAAAAAAABB2LUgAAAAAAAAi6fqGeQF9r+3DBxsbGEM8EAABEirbc4PIPKe4WshQAAAhUd7OU6xelmpqaJEmZmZkhngkAAIg0TU1NSkpKCvU0QoosBQAAeqqrLOUxl/8K0Ofz6fjx40pISJDH4+n1/Tc2NiozM1PHjh1TYmJir+8/3FCvu1Gvu1Gvu1Fv7zIzNTU1KSMjQ1FRV/bZDshSvYt63Y163Y163Y16e1d3s5Trj5SKiorSNddc0+ePk5iYeEU8cdtQr7tRr7tRr7tRb++50o+QakOW6hvU627U627U627U23u6k6Wu7F/9AQAAAAAAICRYlAIAAAAAAEDQsSh1mbxer0pLS+X1ekM9laCgXnejXnejXnejXkSqK62X1Otu1Otu1Otu1Bsarj/ROQAAAAAAAMIPR0oBAAAAAAAg6FiUAgAAAAAAQNCxKAUAAAAAAICgY1GqAytWrNC1116r2NhY5eXlaffu3Zccv2HDBt14442KjY3ViBEj9PrrrztuNzM9+eSTSk9PV1xcnAoKCnT48OG+LCEggdT7m9/8RnfeeaeSk5OVnJysgoKCduPvv/9+eTwex6WoqKivy+i2QOpdt25du1piY2MdY9zU3/Hjx7er1+PxaOrUqf4x4drft99+W3fffbcyMjLk8Xi0adOmLu9TXV2tW265RV6vV9dff73WrVvXbkygPw+CJdB6X3nlFU2aNElXXXWVEhMTlZ+fry1btjjGLF68uF1vb7zxxj6sovsCrbe6urrD53JDQ4NjXLj2Vwq85o5emx6PRzk5Of4x4drjJUuW6LbbblNCQoIGDx6s4uJiHTp0qMv7Rfr7r1uRo8hRbchRkZOjJLIUWcop0rPUlZSjpMjOUixKXeQPf/iDHnnkEZWWlmrv3r0aNWqUCgsLdfLkyQ7H//nPf9a9996rBx98ULW1tSouLlZxcbH279/vH/PTn/5Uv/zlL/Xcc8/pnXfeUXx8vAoLC3Xu3LlgldWpQOutrq7Wvffeq+3bt2vnzp3KzMzU5MmT9c9//tMxrqioSB9//LH/Ul5eHoxyuhRovZKUmJjoqOWDDz5w3O6m/r7yyiuOWvfv36/o6Gh94xvfcIwLx/62tLRo1KhRWrFiRbfG19fXa+rUqZowYYL27dunRYsWac6cOY5w0ZPnS7AEWu/bb7+tSZMm6fXXX9eePXs0YcIE3X333aqtrXWMy8nJcfT2T3/6U19MP2CB1tvm0KFDjnoGDx7svy2c+ysFXvMvfvELR63Hjh3ToEGD2r1+w7HHO3bs0Pz587Vr1y5t3bpVX3zxhSZPnqyWlpZO7xPp779uRY4iR12MHBUZOUoiS3WFLBVZWepKylFShGcpg0Nubq7Nnz/ff721tdUyMjJsyZIlHY6fPn26TZ061bEtLy/Pvv3tb5uZmc/ns7S0NPvZz37mv/306dPm9XqtvLy8DyoITKD1Xuy///2vJSQk2PPPP+/fVlJSYtOmTevtqfaKQOtdu3atJSUldbo/t/d3+fLllpCQYM3Nzf5t4dzfNpJs48aNlxzz/e9/33JychzbZsyYYYWFhf7rl/v9C5bu1NuRm266ycrKyvzXS0tLbdSoUb03sT7SnXq3b99ukuzf//53p2Mipb9mPevxxo0bzePx2D/+8Q//tkjp8cmTJ02S7dixo9Mxkf7+61bkKHLUhchRkZmjzMhS3UWWcm9/IzlHmUVWluJIqQv85z//0Z49e1RQUODfFhUVpYKCAu3cubPD++zcudMxXpIKCwv94+vr69XQ0OAYk5SUpLy8vE73GSw9qfdiZ8+e1RdffKFBgwY5tldXV2vw4MHKzs7WvHnz9Omnn/bq3Huip/U2NzcrKytLmZmZmjZtmt5//33/bW7v7+rVqzVz5kzFx8c7todjfwPV1Wu3N75/4czn86mpqanda/fw4cPKyMjQ0KFDNWvWLH344YchmmHvGD16tNLT0zVp0iTV1NT4t7u9v9L5129BQYGysrIc2yOhx2fOnJGkds/PC0Xy+69bkaPIUR0hR7kzR0lkKbKUu/sbyTlKiqwsxaLUBU6dOqXW1lalpqY6tqemprb729k2DQ0Nlxzf9m8g+wyWntR7sR/84AfKyMhwPFGLior029/+VlVVVXr66ae1Y8cOTZkyRa2trb06/0D1pN7s7GytWbNGmzdv1u9//3v5fD6NHTtWH330kSR393f37t3av3+/5syZ49gerv0NVGev3cbGRn322We98voIZ8uWLVNzc7OmT5/u35aXl6d169apsrJSK1euVH19ve688041NTWFcKY9k56erueee04vv/yyXn75ZWVmZmr8+PHau3evpN75+RfOjh8/rjfeeKPd6zcSeuzz+bRo0SLdfvvtuvnmmzsdF8nvv25FjjqPHPU/5Cj35iiJLEWWcm9/IzlHSZGXpfr12p5wxVm6dKkqKipUXV3tOGnlzJkz/V+PGDFCI0eO1HXXXafq6mpNnDgxFFPtsfz8fOXn5/uvjx07VsOHD9evf/1rPfXUUyGcWd9bvXq1RowYodzcXMd2N/X3SvXiiy+qrKxMmzdvdpwXYMqUKf6vR44cqby8PGVlZWn9+vV68MEHQzHVHsvOzlZ2drb/+tixY3X06FEtX75cv/vd70I4s+B4/vnnNXDgQBUXFzu2R0KP58+fr/3794fNORqAvkKOIkdFen+vZGQpd2epSM5RUuRlKY6UukBKSoqio6N14sQJx/YTJ04oLS2tw/ukpaVdcnzbv4HsM1h6Um+bZcuWaenSpXrzzTc1cuTIS44dOnSoUlJSdOTIkcue8+W4nHrb9O/fX1/5ylf8tbi1vy0tLaqoqOjWD9dw6W+gOnvtJiYmKi4urleeL+GooqJCc+bM0fr169sdrnuxgQMH6oYbboi43nYmNzfXX4tb+yud/5SUNWvWaPbs2YqJibnk2HDr8YIFC/THP/5R27dv1zXXXHPJsZH8/utW5KjzyFGdI0e1Fy797QmyFFnKjf2N5BwlRWaWYlHqAjExMbr11ltVVVXl3+bz+VRVVeX4Lc+F8vPzHeMlaevWrf7xQ4YMUVpammNMY2Oj3nnnnU73GSw9qVc6fwb+p556SpWVlRozZkyXj/PRRx/p008/VXp6eq/Mu6d6Wu+FWltbVVdX56/Fjf2Vzn806Oeff6777ruvy8cJl/4GqqvXbm88X8JNeXm5HnjgAZWXlzs+nrozzc3NOnr0aMT1tjP79u3z1+LG/rbZsWOHjhw50q3/DIVLj81MCxYs0MaNG/XWW29pyJAhXd4nkt9/3YocRY7qCjmqvXDpb0+QpchSbuuvFJk5SorwLNVrp0x3iYqKCvN6vbZu3Tr729/+ZnPnzrWBAwdaQ0ODmZnNnj3bHnvsMf/4mpoa69evny1btswOHDhgpaWl1r9/f6urq/OPWbp0qQ0cONA2b95s7733nk2bNs2GDBlin332WdDru1ig9S5dutRiYmLspZdeso8//th/aWpqMjOzpqYme/TRR23nzp1WX19v27Zts1tuucWGDRtm586dC0mNFwq03rKyMtuyZYsdPXrU9uzZYzNnzrTY2Fh7//33/WPc1N82d9xxh82YMaPd9nDub1NTk9XW1lptba1JsmeffdZqa2vtgw8+MDOzxx57zGbPnu0f//e//90GDBhg3/ve9+zAgQO2YsUKi46OtsrKSv+Yrr5/oRRovS+88IL169fPVqxY4Xjtnj592j/mu9/9rlVXV1t9fb3V1NRYQUGBpaSk2MmTJ4Ne38UCrXf58uW2adMmO3z4sNXV1dnChQstKirKtm3b5h8Tzv01C7zmNvfdd5/l5eV1uM9w7fG8efMsKSnJqqurHc/Ps2fP+se47f3XrchR5ChyVGTmqLb5kaXIUm0iPUtdSTnKLLKzFItSHfjVr35lX/7yly0mJsZyc3Nt165d/tvGjRtnJSUljvHr16+3G264wWJiYiwnJ8dee+01x+0+n8+eeOIJS01NNa/XaxMnTrRDhw4Fo5RuCaTerKwsk9TuUlpaamZmZ8+etcmTJ9tVV11l/fv3t6ysLPvWt74VFj+Y2gRS76JFi/xjU1NT7a677rK9e/c69uem/pqZHTx40CTZm2++2W5f4dzfto+tvfjSVl9JSYmNGzeu3X1Gjx5tMTExNnToUFu7dm27/V7q+xdKgdY7bty4S443O/8xzunp6RYTE2NXX321zZgxw44cORLcwjoRaL1PP/20XXfddRYbG2uDBg2y8ePH21tvvdVuv+HaX7OePadPnz5tcXFxtmrVqg73Ga497qhOSY7XpBvff92KHEWOakOOcgr3/pKlyFJuylJXUo4yi+ws5fn/AgAAAAAAAICg4ZxSAAAAAAAACDoWpQAAAAAAABB0LEoBAAAAAAAg6FiUAgAAAAAAQNCxKAUAAAAAAICgY1EKAAAAAAAAQceiFAAAAAAAAIKORSkAAAAAAAAEHYtSABAgj8ejTZs2hXoaAAAAEYksBaANi1IAIsr9998vj8fT7lJUVBTqqQEAAIQ9shSAcNIv1BMAgEAVFRVp7dq1jm1erzdEswEAAIgsZCkA4YIjpQBEHK/Xq7S0NMclOTlZ0vnDwVeuXKkpU6YoLi5OQ4cO1UsvveS4f11dnb761a8qLi5OX/rSlzR37lw1Nzc7xqxZs0Y5OTnyer1KT0/XggULHLefOnVKX/va1zRgwAANGzZMr776at8WDQAA0EvIUgDCBYtSAFzniSee0D333KN3331Xs2bN0syZM3XgwAFJUktLiwoLC5WcnKy//OUv2rBhg7Zt2+YISitXrtT8+fM1d+5c1dXV6dVXX9X111/veIyysjJNnz5d7733nu666y7NmjVL//rXv4JaJwAAQF8gSwEIGgOACFJSUmLR0dEWHx/vuPzkJz8xMzNJ9tBDDznuk5eXZ/PmzTMzs1WrVllycrI1Nzf7b3/ttdcsKirKGhoazMwsIyPDfvzjH3c6B0n2+OOP+683NzebJHvjjTd6rU4AAIC+QJYCEE44pxSAiDNhwgStXLnSsW3QoEH+r/Pz8x235efna9++fZKkAwcOaNSoUYqPj/fffvvtt8vn8+nQoUPyeDw6fvy4Jk6ceMk5jBw50v91fHy8EhMTdfLkyZ6WBAAAEDRkKQDhgkUpABEnPj6+3SHgvSUuLq5b4/r37++47vF45PP5+mJKAAAAvYosBSBccE4pAK6za9eudteHDx8uSRo+fLjeffddtbS0+G+vqalRVFSUsrOzlZCQoGuvvVZVVVVBnTMAAEC4IEsBCBaOlAIQcT7//HM1NDQ4tvXr108pKSmSpA0bNmjMmDG644479MILL2j37t1avXq1JGnWrFkqLS1VSUmJFi9erE8++UQPP/ywZs+erdTUVEnS4sWL9dBDD2nw4MGaMmWKmpqaVFNTo4cffji4hQIAAPQBshSAcMGiFICIU1lZqfT0dMe27OxsHTx4UNL5T3OpqKjQd77zHaWnp6u8vFw33XSTJGnAgAHasmWLFi5cqNtuu00DBgzQPffco2effda/r5KSEp07d07Lly/Xo48+qpSUFH39618PXoEAAAB9iCwFIFx4zMxCPQkA6C0ej0cbN25UcXFxqKcCAAAQcchSAIKJc0oBAAAAAAAg6FiUAgAAAAAAQNDx53sAAAAAAAAIOo6UAgAAAAAAQNCxKAUAAAAAAICgY1EKAAAAAAAAQceiFAAAAAAAAIKORSkAAAAAAAAEHYtSAAAAAAAACDoWpQAAAAAAABB0LEoBAAAAAAAg6FiUAgAAAAAAQND9HyWBXZ8ZQKriAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import torch\nimport os\nimport json\nimport numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ndef save_model_and_config(model, tokenizer, config, save_dir=\"poetry_model\"):\n    \"\"\"\n    Save the model, tokenizer, and configuration\n    \"\"\"\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # Save model state\n    torch.save(model.state_dict(), os.path.join(save_dir, \"model_weights.pth\"))\n    \n    # Save model configuration\n    model_config = {\n        \"vocab_size\": len(tokenizer.word_index) + 1,\n        \"embedding_dim\": config['embedding_dim'],\n        \"hidden_dim\": config['hidden_dim'],\n        \"num_layers\": config['num_layers'],\n        \"dropout\": config['dropout']\n    }\n    \n    with open(os.path.join(save_dir, \"model_config.json\"), \"w\", encoding='utf-8') as f:\n        json.dump(model_config, f, ensure_ascii=False, indent=4)\n    \n    # Save tokenizer configuration\n    tokenizer_config = {\n        \"word_index\": tokenizer.word_index,\n        \"index_word\": tokenizer.index_word\n    }\n    \n    with open(os.path.join(save_dir, \"tokenizer_config.json\"), \"w\", encoding='utf-8') as f:\n        json.dump(tokenizer_config, f, ensure_ascii=False, indent=4)\n    \n    # Save training configuration\n    with open(os.path.join(save_dir, \"training_config.json\"), \"w\", encoding='utf-8') as f:\n        json.dump(config, f, ensure_ascii=False, indent=4)\n\ndef load_saved_model(save_dir=\"poetry_model\"):\n    \"\"\"\n    Load the saved model, tokenizer, and configurations\n    \"\"\"\n    # Load model configuration\n    with open(os.path.join(save_dir, \"model_config.json\"), \"r\", encoding='utf-8') as f:\n        model_config = json.load(f)\n    \n    # Initialize model with saved configuration\n    model = PoetryLSTM(\n        vocab_size=model_config[\"vocab_size\"],\n        embedding_dim=model_config[\"embedding_dim\"],\n        hidden_dim=model_config[\"hidden_dim\"],\n        num_layers=model_config[\"num_layers\"],\n        dropout=model_config[\"dropout\"],\n        seq_length=None  # Will be determined during generation\n    )\n    \n    # Load model weights\n    model.load_state_dict(torch.load(os.path.join(save_dir, \"model_weights.pth\")))\n    \n    # Load tokenizer configuration\n    with open(os.path.join(save_dir, \"tokenizer_config.json\"), \"r\", encoding='utf-8') as f:\n        tokenizer_config = json.load(f)\n    \n    return model, tokenizer_config\n\ndef generate_poetry(model, tokenizer_config, seed_text, max_length=50, temperature=0.7):\n    \"\"\"\n    Generate poetry with temperature-based sampling and improved output formatting\n    \n    Args:\n        model: Loaded poetry model\n        tokenizer_config: Loaded tokenizer configuration\n        seed_text: Starting text for generation\n        max_length: Maximum number of words to generate\n        temperature: Controls randomness (higher = more creative)\n    \"\"\"\n    model.eval()\n    \n    # Create reverse word index\n    index_word = {int(k): v for k, v in tokenizer_config[\"index_word\"].items()}\n    word_index = tokenizer_config[\"word_index\"]\n    \n    # Convert seed text to sequence\n    words = seed_text.lower().split()\n    current_sequence = [word_index.get(word, 1) for word in words]  # 1 is usually OOV token\n    \n    generated_words = words.copy()\n    device = next(model.parameters()).device\n    \n    for _ in range(max_length):\n        # Prepare input sequence\n        padded_sequence = pad_sequences([current_sequence], maxlen=max(len(current_sequence), 1), padding='pre')\n        input_tensor = torch.tensor(padded_sequence, dtype=torch.long).to(device)\n        \n        # Get model predictions\n        with torch.no_grad():\n            output, _ = model(input_tensor)\n            \n            # Apply temperature\n            output = output / temperature\n            \n            # Convert to probabilities\n            probs = torch.softmax(output[0], dim=-1)\n            \n            # Sample from the distribution\n            predicted_index = torch.multinomial(probs, 1).item()\n        \n        # Get the predicted word\n        predicted_word = index_word.get(predicted_index, \"\")\n        \n        if not predicted_word or predicted_word == \"\":\n            continue\n            \n        generated_words.append(predicted_word)\n        \n        # Update current sequence\n        current_sequence.append(predicted_index)\n        if len(current_sequence) > max_length:\n            current_sequence = current_sequence[1:]\n    \n    # Format the generated poetry\n    return format_poetry(\" \".join(generated_words))\n\ndef format_poetry(text, max_line_length=40):\n    \"\"\"\n    Format the generated text into poetry-like structure\n    \"\"\"\n    words = text.split()\n    lines = []\n    current_line = []\n    current_length = 0\n    \n    for word in words:\n        if current_length + len(word) + 1 > max_line_length:\n            lines.append(\" \".join(current_line))\n            current_line = [word]\n            current_length = len(word)\n        else:\n            current_line.append(word)\n            current_length += len(word) + 1\n    \n    if current_line:\n        lines.append(\" \".join(current_line))\n    \n    return \"\\n\".join(lines)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:02:45.644417Z","iopub.execute_input":"2025-02-08T17:02:45.644736Z","iopub.status.idle":"2025-02-08T17:02:45.658944Z","shell.execute_reply.started":"2025-02-08T17:02:45.644708Z","shell.execute_reply":"2025-02-08T17:02:45.658166Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Save the model after training\nsave_model_and_config(model, tokenizer, config)\n\n# Later, load the model and generate poetry\nloaded_model, loaded_tokenizer = load_saved_model()\n\n# Generate poetry with different temperatures\nseed_texts = [\n    \"dil ki baat\",\n    \"zindagi ka safar\",\n    \"mohabbat ka rang\",\n    \"khushiyan aur gham\"\n]\n\nprint(\"\\nGenerating poetry with different temperatures:\")\ntemperatures = [0.5, 0.7, 1.0]\n\nfor seed_text in seed_texts:\n    print(f\"\\nSeed Text: {seed_text}\")\n    for temp in temperatures:\n        print(f\"\\nTemperature: {temp}\")\n        generated_poem = generate_poetry(\n            loaded_model,\n            loaded_tokenizer,\n            seed_text,\n            max_length=50,\n            temperature=temp\n        )\n        print(\"Generated Poetry:\")\n        print(\"-\" * 40)\n        print(generated_poem)\n        print(\"-\" * 40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T17:02:49.850243Z","iopub.execute_input":"2025-02-08T17:02:49.850523Z","iopub.status.idle":"2025-02-08T17:02:54.857373Z","shell.execute_reply.started":"2025-02-08T17:02:49.850500Z","shell.execute_reply":"2025-02-08T17:02:54.856630Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-16-7825183f862c>:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(os.path.join(save_dir, \"model_weights.pth\")))\n","output_type":"stream"},{"name":"stdout","text":"\nGenerating poetry with different temperatures:\n\nSeed Text: dil ki baat\n\nTemperature: 0.5\nGenerated Poetry:\n----------------------------------------\ndil ki baat hai aisī se hai dekhte e\nhuī haiñ ham nahīñ e e hai ke haiñ meñ\nhai e hai e to us hai ki e sahī se ga ī\nho aur hai e e ke hai na dil e to ke ke\nse e na aaj e un e dil\n----------------------------------------\n\nTemperature: 0.7\nGenerated Poetry:\n----------------------------------------\ndil ki baat hai ye ko bhī ho dil ko\nmiyāñ na dekhī mauj kī ḳhushk jāh e meñ\nke ke kaam hai ho ke e hai ho e hai bād\nhai fuġhāñ hai hosh us manzil tabī e\nsivā e ḳhūñ apnī dil kyuuñ ho mahshar\nhoñgī āñgan hai haal thā ke\n----------------------------------------\n\nTemperature: 1.0\nGenerated Poetry:\n----------------------------------------\ndil ki baat ke e tū bhī tambūra e\ngarebāñ e nigūnī hare e log pahchān thā\nsahī ubhārnā kī bahaltī shaguftan pe\nraihān ham kyā muft thī sapne phir baith\nsamjhā aql phir kyā bhī duuñ ne kisī e\nqarār yaad raah o varna na tūr e us bhī\ne'tibār kyā guuna\n----------------------------------------\n\nSeed Text: zindagi ka safar\n\nTemperature: 0.5\nGenerated Poetry:\n----------------------------------------\nzindagi ka safar dil ye e e e kyā ho e\ntire e e e ko ko e ko ki maiñ bhī na ne\nto gauhar e e se e ho rahe hai hai dil\nki meñ e kar ke e kisī mirī tirī hai hai\nkaun e dil hai ko vo nahīñ\n----------------------------------------\n\nTemperature: 0.7\nGenerated Poetry:\n----------------------------------------\nzindagi ka safar vasl e e hī kyuuñ bhī\nek lafz pinhāñ jo to hai ko hai o piyūñ\nkā aur daaġh agar apnī e meñ gumānī rañg\nke shoḳh e e vahī e haiñ o kah bhī e e\nbhī hai e e na dil hamesha dil ko bālīñ\nbhī na hai\n----------------------------------------\n\nTemperature: 1.0\nGenerated Poetry:\n----------------------------------------\nzindagi ka safar na bujhā hai ki mahfil\nphir ga ī ḳhayāl jī paa ham salīqa hai\nphirte baḳhīlī dil huā milan māñge terī\nmat ki chup kuchh pighalnā kā gaa be\npaḍe be ko ishq nazar galī aql phirā\nbahlā ko khile dil gayā hai bahut subuk\nko gayā e kahīñ maiñ\n----------------------------------------\n\nSeed Text: mohabbat ka rang\n\nTemperature: 0.5\nGenerated Poetry:\n----------------------------------------\nmohabbat ka rang bhī to na hai na hai\nke dil ki e to ko ho se ye bhī meñ hai\nkā bhī jā kar ga ī hai e e e dil jahāñ\nkabhī be dil hai bhī e e hai ke se e hai\ne kuchh ye ko haiñ e e hai\n----------------------------------------\n\nTemperature: 0.7\nGenerated Poetry:\n----------------------------------------\nmohabbat ka rang e kī chuke ho yahāñ e\nho ke hai ke ke kī hai rahguzar sarshār\nho dushman e nahīñ e se ḳhāna ḳhushbū\nhaiñ nahīñ ki agar ko jo e e se dil\nnahīñ meñ hai har aur nahīñ ki jis kyā\nke hai hai hai ho nahīñ ab burā\n----------------------------------------\n\nTemperature: 1.0\nGenerated Poetry:\n----------------------------------------\nmohabbat ka rang bhī to panāh meñ charb\ndī kab subūr e gir vo se us agar allāh\nke bazm nashshe na barbād kaun rotā ke\nthā had ne na vo taar koī ba ijz ye\nilaah e tere e bhī le dekho faqat sāmāñ\nh kis kā makr fishāñ nafas jaanā egā\n----------------------------------------\n\nSeed Text: khushiyan aur gham\n\nTemperature: 0.5\nGenerated Poetry:\n----------------------------------------\nkhushiyan aur gham dil hai ye hai hai\nto vo hai haath ko bulbul ye hai hai bhī\nke e dil meñ e se e to hai hai to dil\nmeñ na dil se ke e ko e us ho ki ke e ye\nkā kā bhī hai ga ī hai hai us\n----------------------------------------\n\nTemperature: 0.7\nGenerated Poetry:\n----------------------------------------\nkhushiyan aur gham e ko se e niyāz\nkuchh haiñ meñ se hue nahīñ kā tamannā\nto hai kā kā kyā hasrat e kār ko to kā\n'farāz' meñ haqīqat magar pahle taraf\nphir se to se dil meñ ki e aa phir\nāshiyāñ hai nihāñ meñ us ke javāb par\nhai hai\n----------------------------------------\n\nTemperature: 1.0\nGenerated Poetry:\n----------------------------------------\nkhushiyan aur gham uḍāne se māl haa\nqahqahoñ e ābādī ho zaḳhm ke e javān e\nse naam kā ho ham ne kāñptā sab tajāhul\nmerī ho ġhuncha dañg jā ḳhāk chukā tujh\nkabhī āġhāz hai ki e kuchh unvān sab se\njaan na dost puḳhtagī harīm durūd hadaf\nnafas dhaan andesha meñ\n----------------------------------------\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}